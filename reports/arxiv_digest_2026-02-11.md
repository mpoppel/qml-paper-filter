# arXiv Daily Digest - 2026-02-11

**Search Period:** Last 7 days  
**Papers Found:** 30

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Preventing Barren Plateaus in Continuous Quantum Generative Models](http://arxiv.org/abs/2602.10049v1)
**Authors:** Olli Hirviniemi, Afrad Basheer, Thomas Cope  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph  

**Abstract:** Recent developments in the field of variational quantum circuits (VQCs) have shifted the prerequisites for trainability for many barren plateau-free models onto the data encoding state fed into a classically trainable unitary. By strengthening proofs relating to small-angle initialisation, we provide a full circuit model which does not suffer from barren plateaus and is robust against current clas...

[View on arXiv](http://arxiv.org/abs/2602.10049v1) | [PDF](https://arxiv.org/pdf/2602.10049v1)

---

### [Position: Message-passing and spectral GNNs are two sides of the same coin](http://arxiv.org/abs/2602.10031v1)
**Authors:** Antonis Vasileiou, Juan Cervino, Pascal Frossard et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG  

**Abstract:** Graph neural networks (GNNs) are commonly divided into message-passing neural networks (MPNNs) and spectral graph neural networks, reflecting two largely separate research traditions in machine learning and signal processing. This paper argues that this divide is mostly artificial, hindering progress in the field. We propose a viewpoint in which both MPNNs and spectral GNNs are understood as diffe...

[View on arXiv](http://arxiv.org/abs/2602.10031v1) | [PDF](https://arxiv.org/pdf/2602.10031v1)

---

### [WildCat: Near-Linear Attention in Theory and Practice](http://arxiv.org/abs/2602.10056v1)
**Authors:** Tobias Schröder, Lester Mackey  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, stat.ML  

**Abstract:** We introduce WildCat, a high-accuracy, low-cost approach to compressing the attention mechanism in neural networks. While attention is a staple of modern network architectures, it is also notoriously expensive to deploy due to resource requirements that scale quadratically with the input sequence length $n$. WildCat avoids these quadratic costs by only attending over a small weighted coreset. Cruc...

[View on arXiv](http://arxiv.org/abs/2602.10056v1) | [PDF](https://arxiv.org/pdf/2602.10056v1)

---

### [Supervised Metric Regularization Through Alternating Optimization for Multi-Regime Physics-Informed Neural Networks](http://arxiv.org/abs/2602.09980v1)
**Authors:** Enzo Nicolas Spotorno, Josafat Ribeiro Leal, Antonio Augusto Frohlich  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.AI, physics.comp-ph  

**Abstract:** Standard Physics-Informed Neural Networks (PINNs) often face challenges when modeling parameterized dynamical systems with sharp regime transitions, such as bifurcations. In these scenarios, the continuous mapping from parameters to solutions can result in spectral bias or "mode collapse", where the network averages distinct physical behaviors. We propose a Topology-Aware PINN (TAPINN) that aims t...

[View on arXiv](http://arxiv.org/abs/2602.09980v1) | [PDF](https://arxiv.org/pdf/2602.09980v1)

---

### [Disentangling orbital and confinement contributions to $g$-factor in Ge/SiGe hole quantum dots](http://arxiv.org/abs/2602.09913v1)
**Authors:** L. Sommer, I. Seidler, F. J. Schupp et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cond-mat.mes-hall, quant-ph  

**Abstract:** Spin qubits are typically operated in the lowest orbital of a quantum dot to minimize interference from nearby states. In valence-band hole systems, strong spin-orbit coupling links spin and orbital degrees of freedom, strongly influencing the hole $g$-factor, a key parameter for qubit control. We investigate the out-of-plane $g$-factor in Ge quantum dots using excitation (single-particle) and add...

[View on arXiv](http://arxiv.org/abs/2602.09913v1) | [PDF](https://arxiv.org/pdf/2602.09913v1)

---

### [Biases in the Blind Spot: Detecting What LLMs Fail to Mention](http://arxiv.org/abs/2602.10117v1)
**Authors:** Iván Arcuschin, David Chanin, Adrià Garriga-Alonso et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.AI  

**Abstract:** Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipe...

[View on arXiv](http://arxiv.org/abs/2602.10117v1) | [PDF](https://arxiv.org/pdf/2602.10117v1)

---

### [Anyon Permutations in Quantum Double Models through Constant-depth Circuits](http://arxiv.org/abs/2602.10110v1)
**Authors:** Yabo Li, Zijian Song  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph, cond-mat.str-el  

**Abstract:** We provide explicit constant-depth local unitary circuits that realize general anyon permutations in Kitaev's quantum double models. This construction can be naturally understood through a correspondence between anyon permutation symmetries of two-dimensional topological orders and self-dualities in one-dimensional systems, where local gates implement self-duality transformations on the boundaries...

[View on arXiv](http://arxiv.org/abs/2602.10110v1) | [PDF](https://arxiv.org/pdf/2602.10110v1)

---

### [Olaf-World: Orienting Latent Actions for Video World Modeling](http://arxiv.org/abs/2602.10104v1)
**Authors:** Yuxin Jiang, Yuchao Gu, Ivor W. Tsang et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.CV, cs.AI, cs.LG  

**Abstract:** Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to ...

[View on arXiv](http://arxiv.org/abs/2602.10104v1) | [PDF](https://arxiv.org/pdf/2602.10104v1)

---

### [Towards Explainable Federated Learning: Understanding the Impact of Differential Privacy](http://arxiv.org/abs/2602.10100v1)
**Authors:** Júlio Oliveira, Rodrigo Ferreira, André Riker et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.CR  

**Abstract:** Data privacy and eXplainable Artificial Intelligence (XAI) are two important aspects for modern Machine Learning systems. To enhance data privacy, recent machine learning models have been designed as a Federated Learning (FL) system. On top of that, additional privacy layers can be added, via Differential Privacy (DP). On the other hand, to improve explainability, ML must consider more interpretab...

[View on arXiv](http://arxiv.org/abs/2602.10100v1) | [PDF](https://arxiv.org/pdf/2602.10100v1)

---

### [Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders](http://arxiv.org/abs/2602.10099v1)
**Authors:** Amandeep Kumar, Vishal M. Patel  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.CV  

**Abstract:** Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric....

[View on arXiv](http://arxiv.org/abs/2602.10099v1) | [PDF](https://arxiv.org/pdf/2602.10099v1)

---

### [Step-resolved data attribution for looped transformers](http://arxiv.org/abs/2602.10097v1)
**Authors:** Georgios Kaissis, David Mildenberger, Juan Felipe Gomez et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.AI  

**Abstract:** We study how individual training examples shape the internal computation of looped transformers, where a shared block is applied for $τ$ recurrent iterations to enable latent reasoning. Existing training-data influence estimators such as TracIn yield a single scalar score that aggregates over all loop iterations, obscuring when during the recurrent computation a training example matters. We introd...

[View on arXiv](http://arxiv.org/abs/2602.10097v1) | [PDF](https://arxiv.org/pdf/2602.10097v1)

---

### [Causality in Video Diffusers is Separable from Denoising](http://arxiv.org/abs/2602.10095v1)
**Authors:** Xingjian Bai, Guande He, Zhengqi Li et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.CV, cs.AI, cs.LG  

**Abstract:** Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we...

[View on arXiv](http://arxiv.org/abs/2602.10095v1) | [PDF](https://arxiv.org/pdf/2602.10095v1)

---

### [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](http://arxiv.org/abs/2602.10090v1)
**Authors:** Zhaoyang Wang, Canwen Xu, Boyi Liu et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.AI, cs.CL, cs.LG  

**Abstract:** Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale ...

[View on arXiv](http://arxiv.org/abs/2602.10090v1) | [PDF](https://arxiv.org/pdf/2602.10090v1)

---

### [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](http://arxiv.org/abs/2602.10085v1)
**Authors:** Richard Bornemann, Pierluigi Vito Amadori, Antoine Cully  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.AI  

**Abstract:** Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. Whil...

[View on arXiv](http://arxiv.org/abs/2602.10085v1) | [PDF](https://arxiv.org/pdf/2602.10085v1)

---

### [Anagent For Enhancing Scientific Table & Figure Analysis](http://arxiv.org/abs/2602.10081v1)
**Authors:** Xuehang Guo, Zhiyong Lu, Tom Hope et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.CL, cs.AI  

**Abstract:** In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heteroge...

[View on arXiv](http://arxiv.org/abs/2602.10081v1) | [PDF](https://arxiv.org/pdf/2602.10081v1)

---

### [Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability](http://arxiv.org/abs/2602.10067v1)
**Authors:** Aaditya Vikram Prasad, Connor Watts, Jack Merullo et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG  

**Abstract:** Language models trained on large-scale datasets have been shown to learn features that encode abstract concepts such as factuality or intent. Such features are traditionally used for test-time monitoring or steering. We present an alternative affordance: features as scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet open-ended behavior an...

[View on arXiv](http://arxiv.org/abs/2602.10067v1) | [PDF](https://arxiv.org/pdf/2602.10067v1)

---

### [Vendi Novelty Scores for Out-of-Distribution Detection](http://arxiv.org/abs/2602.10062v1)
**Authors:** Amey P. Pasarkar, Adji Bousso Dieng  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.CV  

**Abstract:** Out-of-distribution (OOD) detection is critical for the safe deployment of machine learning systems. Existing post-hoc detectors typically rely on model confidence scores or likelihood estimates in feature space, often under restrictive distributional assumptions. In this work, we introduce a third paradigm and formulate OOD detection from a diversity perspective. We propose the Vendi Novelty Scor...

[View on arXiv](http://arxiv.org/abs/2602.10062v1) | [PDF](https://arxiv.org/pdf/2602.10062v1)

---

### [Evaluating Disentangled Representations for Controllable Music Generation](http://arxiv.org/abs/2602.10058v1)
**Authors:** Laura Ibáñez-Martínez, Chukwuemeka Nkama, Andrea Poltronieri et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.SD, cs.LG, eess.AS  

**Abstract:** Recent approaches in music generation rely on disentangled representations, often labeled as structure and timbre or local and global, to enable controllable synthesis. Yet the underlying properties of these embeddings remain underexplored. In this work, we evaluate such disentangled representations in a set of music audio models for controllable generation using a probing-based framework that goe...

[View on arXiv](http://arxiv.org/abs/2602.10058v1) | [PDF](https://arxiv.org/pdf/2602.10058v1)

---

### [Long Chain-of-Thought Compression via Fine-Grained Group Policy Optimization](http://arxiv.org/abs/2602.10048v1)
**Authors:** Xinchen Han, Hossam Afifi, Michel Marot et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.AI  

**Abstract:** Large Language Models (LLMs) often generate unnecessarily verbose Chain-of-Thought (CoT) reasoning that increases computational costs and latency without proportional performance gains. In this paper, we propose \textbf{F}ine-grained \textbf{G}roup policy \textbf{O}ptimization (\textbf{FGO}), a Reinforcement Learning (RL) algorithm that refines group responses by subdividing them and assigning app...

[View on arXiv](http://arxiv.org/abs/2602.10048v1) | [PDF](https://arxiv.org/pdf/2602.10048v1)

---

### [Conformal Prediction Sets for Instance Segmentation](http://arxiv.org/abs/2602.10045v1)
**Authors:** Kerri Lu, Dan M. Kluger, Stephen Bates et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.CV, cs.LG, stat.ME, stat.ML  

**Abstract:** Current instance segmentation models achieve high performance on average predictions, but lack principled uncertainty quantification: their outputs are not calibrated, and there is no guarantee that a predicted mask is close to the ground truth. To address this limitation, we introduce a conformal prediction algorithm to generate adaptive confidence sets for instance segmentation. Given an image a...

[View on arXiv](http://arxiv.org/abs/2602.10045v1) | [PDF](https://arxiv.org/pdf/2602.10045v1)

---

### [Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning](http://arxiv.org/abs/2602.10044v1)
**Authors:** Akshay Mete, Shahid Aamir Sheikh, Tzu-Hsiang Lin et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cs.AI, eess.SY  

**Abstract:** Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation (RBMLE) from adaptive control into deep RL. In contrast to upper confidence bound (UCB)-style explor...

[View on arXiv](http://arxiv.org/abs/2602.10044v1) | [PDF](https://arxiv.org/pdf/2602.10044v1)

---

### [Effectiveness of Binary Autoencoders for QUBO-Based Optimization Problems](http://arxiv.org/abs/2602.10037v1)
**Authors:** Tetsuro Abe, Masashi Yamashita, Shu Tanaka  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, cond-mat.stat-mech, quant-ph  

**Abstract:** In black-box combinatorial optimization, objective evaluations are often expensive, so high quality solutions must be found under a limited budget. Factorization machine with quantum annealing (FMQA) builds a quadratic surrogate model from evaluated samples and optimizes it on an Ising machine. However, FMQA requires binary decision variables, and for nonbinary structures such as integer permutati...

[View on arXiv](http://arxiv.org/abs/2602.10037v1) | [PDF](https://arxiv.org/pdf/2602.10037v1)

---

### [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](http://arxiv.org/abs/2602.10021v1)
**Authors:** Wenxuan Xie, Yujia Wang, Xin Tan et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.CL, cs.AI  

**Abstract:** The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge editing, are often constrained in practice by finite context windows, retriever noise, or the risk of ca...

[View on arXiv](http://arxiv.org/abs/2602.10021v1) | [PDF](https://arxiv.org/pdf/2602.10021v1)

---

### [RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments](http://arxiv.org/abs/2602.10015v1)
**Authors:** Dharmendra Sharma, Archit Sharma, John Reberio et al.  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.RO, cs.AI  

**Abstract:** Temporally locating and classifying fine-grained sub-task segments in long, untrimmed videos is crucial to safe human-robot collaboration. Unlike generic activity recognition, collaborative manipulation requires sub-task labels that are directly robot-executable. We present RoboSubtaskNet, a multi-stage human-to-robot sub-task segmentation framework that couples attention-enhanced I3D features (RG...

[View on arXiv](http://arxiv.org/abs/2602.10015v1) | [PDF](https://arxiv.org/pdf/2602.10015v1)

---

### [Emergence of a Luttinger Liquid Phase in an Array of Chiral Molecules](http://arxiv.org/abs/2602.10002v1)
**Authors:** Muhammad Arsalan Ali Akbar, Bretislav Friedrich, Sabre Kais  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph  

**Abstract:** We propose a robust platform for simulating chiral quantum magnetism using linear arrays of trapped asymmetric top molecules, specifically 1,2-propanediol ($\mathrm{C_{3}H_{8}O_{2}}$). By mapping the Stark-dressed rotational states onto an effective spin-$1/2$ subspace, we rigorously derive a generalized $XXZ$ Heisenberg Hamiltonian governing the underlying many-body dynamics. Unlike standard soli...

[View on arXiv](http://arxiv.org/abs/2602.10002v1) | [PDF](https://arxiv.org/pdf/2602.10002v1)

---

### [Universal Foundations of Thermodynamics: Entropy and Energy Beyond Equilibrium and Without Extensivity](http://arxiv.org/abs/2602.09986v1)
**Authors:** Gian Paolo Beretta  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph, cond-mat.stat-mech, physics.chem-ph, physics.class-ph  

**Abstract:** Thermodynamics is commonly presented as a theory of macroscopic systems in stable equilibrium, built upon assumptions of extensivity and scaling with system size. In this paper, we present a universal formulation of the elementary foundations of thermodynamics, in which entropy and energy are defined and employed beyond equilibrium and without assuming extensivity. The formulation applies to all s...

[View on arXiv](http://arxiv.org/abs/2602.09986v1) | [PDF](https://arxiv.org/pdf/2602.09986v1)

---

### [Information Theory of Action : Reconstructing Quantum Dynamics from Inference over Action Space](http://arxiv.org/abs/2602.09984v1)
**Authors:** Fabricio Souza Luiz, Marcos César de Oliveira  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph  

**Abstract:** We develop an information-theoretic reconstruction of quantum dynamics based on inference over action space. The fundamental object is a density of action states encoding the multiplicity of dynamical alternatives between configurations. Maximum-entropy inference introduces a finite resolution scale in action, implying that sufficiently close action contributions are operationally indistinguishabl...

[View on arXiv](http://arxiv.org/abs/2602.09984v1) | [PDF](https://arxiv.org/pdf/2602.09984v1)

---

### [Causal Identification in Multi-Task Demand Learning with Confounding](http://arxiv.org/abs/2602.09969v1)
**Authors:** Varun Gupta, Vijay Kamble  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cs.LG, econ.EM, stat.ML  

**Abstract:** We study a canonical multi-task demand learning problem motivated by retail pricing, in which a firm seeks to estimate heterogeneous linear price-response functions across a large collection of decision contexts. Each context is characterized by rich observable covariates yet typically exhibits only limited historical price variation, motivating the use of multi-task learning to borrow strength ac...

[View on arXiv](http://arxiv.org/abs/2602.09969v1) | [PDF](https://arxiv.org/pdf/2602.09969v1)

---

### [The chiral random walk: A quantum-inspired framework for odd diffusion](http://arxiv.org/abs/2602.09920v1)
**Authors:** Jan Wójcik, Erik Kalz  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** cond-mat.stat-mech, cond-mat.soft, quant-ph  

**Abstract:** Chirality in active and passive fluids gives rise to odd transport properties, most notably the emergence of robust edge currents that defy standard dissipative dynamics. While these phenomena are well-described by continuum hydrodynamics, a microscopic framework connecting them to their topological origins has remained elusive. Here, we present a lattice model for an isotropic chiral random walk ...

[View on arXiv](http://arxiv.org/abs/2602.09920v1) | [PDF](https://arxiv.org/pdf/2602.09920v1)

---

### [Dissipative phase transitions of the Dicke-Ising model](http://arxiv.org/abs/2602.09912v1)
**Authors:** Jun-Ling Wang, Jiong Li, Qing-Hu Chen  
**Published:** 2026-02-10  
**Updated:** 2026-02-10  
**Categories:** quant-ph  

**Abstract:** The dissipative phase transitions in the open transverse and longitudinal Dicke-Ising model (DIM), which incorporates nearest-neighbor Ising-type spin interactions into the Dicke framework, are investigated within a mean-field approach and further validated by detailed stability analysis. While the dissipative phase diagram of the transverse DIM is only slightly shifted upward compared with its gr...

[View on arXiv](http://arxiv.org/abs/2602.09912v1) | [PDF](https://arxiv.org/pdf/2602.09912v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
