# arXiv Daily Digest - 2025-12-09

**Search Period:** Last 7 days  
**Papers Found:** 27

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Graph-Based Learning of Spectro-Topographical EEG Representations with Gradient Alignment for Brain-Computer Interfaces](http://arxiv.org/abs/2512.07820v1)
**Authors:** Prithila Angkan, Amin Jalali, Paul Hungler et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.HC, cs.LG  

**Abstract:** We present a novel graph-based learning of EEG representations with gradient alignment (GEEGA) that leverages multi-domain information to learn EEG representations for brain-computer interfaces. Our model leverages graph convolutional networks to fuse embeddings from frequency-based topographical maps and time-frequency spectrograms, capturing inter-domain relationships. GEEGA addresses the challe...

[View on arXiv](http://arxiv.org/abs/2512.07820v1) | [PDF](https://arxiv.org/pdf/2512.07820v1)

---

### [Fast-feedback protocols for calibration and drift control in quantum computers](http://arxiv.org/abs/2512.07815v1)
**Authors:** Alicia B. Magann, Nathan E. Miller, Robin Blume-Kohout et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph  

**Abstract:** We introduce two classes of lightweight, adaptive calibration protocols for quantum computers that leverage fast feedback. The first enables shot-by-shot updates to device parameters using measurement outcomes from simple, indefinite-outcome quantum circuits. This low-latency approach supports rapid tuning of one or more parameters in real time to mitigate drift. The second protocol updates parame...

[View on arXiv](http://arxiv.org/abs/2512.07815v1) | [PDF](https://arxiv.org/pdf/2512.07815v1)

---

### [LUNA: LUT-Based Neural Architecture for Fast and Low-Cost Qubit Readout](http://arxiv.org/abs/2512.07808v1)
**Authors:** M. A. Farooq, G. Di Guglielmo, A. Rajagopala et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph, cs.LG  

**Abstract:** Qubit readout is a critical operation in quantum computing systems, which maps the analog response of qubits into discrete classical states. Deep neural networks (DNNs) have recently emerged as a promising solution to improve readout accuracy . Prior hardware implementations of DNN-based readout are resource-intensive and suffer from high inference latency, limiting their practical use in low-late...

[View on arXiv](http://arxiv.org/abs/2512.07808v1) | [PDF](https://arxiv.org/pdf/2512.07808v1)

---

### [A scalable and real-time neural decoder for topological quantum codes](http://arxiv.org/abs/2512.07737v1)
**Authors:** Andrew W. Senior, Thomas Edlich, Francisco J. H. Heras et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph, cs.LG  

**Abstract:** Fault-tolerant quantum computing will require error rates far below those achievable with physical qubits. Quantum error correction (QEC) bridges this gap, but depends on decoders being simultaneously fast, accurate, and scalable. This combination of requirements has not yet been met by a machine-learning decoder, nor by any decoder for promising resource-efficient codes such as the colour code. H...

[View on arXiv](http://arxiv.org/abs/2512.07737v1) | [PDF](https://arxiv.org/pdf/2512.07737v1)

---

### [Strongly driven cavity quantum electrodynamical-optomechanical hybrid system](http://arxiv.org/abs/2512.07788v1)
**Authors:** Xuxin Wang, Jiahe Pan, Tobias J. Kippenberg et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph  

**Abstract:** Hybrid quantum systems harness the distinct advantages of different physical platforms, yet their integration is not always trivial due to potential incompatibilities in operational principles. Here, we theoretically propose and demonstrate a scheme for generating non-Gaussian mechanical states using a strongly driven hybrid system that combines cavity quantum electrodynamics (QED) and cavity opto...

[View on arXiv](http://arxiv.org/abs/2512.07788v1) | [PDF](https://arxiv.org/pdf/2512.07788v1)

---

### [Relational Visual Similarity](http://arxiv.org/abs/2512.07833v1)
**Authors:** Thao Nguyen, Sicheng Mo, Krishna Kumar Singh et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CV, cs.AI, cs.LG  

**Abstract:** Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. ...

[View on arXiv](http://arxiv.org/abs/2512.07833v1) | [PDF](https://arxiv.org/pdf/2512.07833v1)

---

### [Do Generalisation Results Generalise?](http://arxiv.org/abs/2512.07832v1)
**Authors:** Matteo Boglioni, Andrea Sgobbi, Gabriel Tavernini et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CL, cs.LG  

**Abstract:** A large language model's (LLM's) out-of-distribution (OOD) generalisation ability is crucial to its deployment. Previous work assessing LLMs' generalisation performance, however, typically focuses on a single out-of-distribution dataset. This approach may fail to precisely evaluate the capabilities of the model, as the data shifts encountered once a model is deployed are much more diverse. In this...

[View on arXiv](http://arxiv.org/abs/2512.07832v1) | [PDF](https://arxiv.org/pdf/2512.07832v1)

---

### [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](http://arxiv.org/abs/2512.07829v1)
**Authors:** Yuan Gao, Chen Chen, Tianrong Chen et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CV, cs.AI  

**Abstract:** Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fu...

[View on arXiv](http://arxiv.org/abs/2512.07829v1) | [PDF](https://arxiv.org/pdf/2512.07829v1)

---

### [The Adoption and Usage of AI Agents: Early Evidence from Perplexity](http://arxiv.org/abs/2512.07828v1)
**Authors:** Jeremy Yang, Noah Yonack, Kate Zyskowski et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.LG, econ.GN  

**Abstract:** This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: W...

[View on arXiv](http://arxiv.org/abs/2512.07828v1) | [PDF](https://arxiv.org/pdf/2512.07828v1)

---

### [An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning](http://arxiv.org/abs/2512.07827v1)
**Authors:** Lukas Johannes Möller  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CR, cs.DC, cs.LG  

**Abstract:** The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence while minimizing cost through autonomous orchestration of infrastructure. The principal contribution...

[View on arXiv](http://arxiv.org/abs/2512.07827v1) | [PDF](https://arxiv.org/pdf/2512.07827v1)

---

### [Comparing quantum channels using Hermitian-preserving trace-preserving linear maps: A physically meaningful approach](http://arxiv.org/abs/2512.07822v1)
**Authors:** Arindam Mitra, Jatin Ghai  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph  

**Abstract:** In quantum technologies, quantum channels are essential elements for the transmission of quantum states. The action of a quantum channel usually introduces noise in the quantum state and thereby reduces the information contained in it. Concatenating a quantum channel with another quantum channel makes it more noisy and degrades its information and resource preservability. These are mathematically ...

[View on arXiv](http://arxiv.org/abs/2512.07822v1) | [PDF](https://arxiv.org/pdf/2512.07822v1)

---

### [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](http://arxiv.org/abs/2512.07821v1)
**Authors:** Shaoheng Fang, Hanwen Jiang, Yunpeng Bai et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CV, cs.AI  

**Abstract:** Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our ex...

[View on arXiv](http://arxiv.org/abs/2512.07821v1) | [PDF](https://arxiv.org/pdf/2512.07821v1)

---

### [Provable Long-Range Benefits of Next-Token Prediction](http://arxiv.org/abs/2512.07818v1)
**Authors:** Xinyuan Cao, Santosh S. Vempala  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.LG, cs.AI, stat.ML  

**Abstract:** Why do modern language models, trained to do well on next-word prediction, appear to generate coherent documents and capture long-range structure? Here we show that next-token prediction is provably powerful for learning longer-range structure, even with common neural network architectures. Specifically, we prove that optimizing next-token prediction over a Recurrent Neural Network (RNN) yields a ...

[View on arXiv](http://arxiv.org/abs/2512.07818v1) | [PDF](https://arxiv.org/pdf/2512.07818v1)

---

### [Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach](http://arxiv.org/abs/2512.07814v1)
**Authors:** Hua Yang, Alejandro Velasco, Sen Fang et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.SE, cs.AI, cs.CR  

**Abstract:** Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks am...

[View on arXiv](http://arxiv.org/abs/2512.07814v1) | [PDF](https://arxiv.org/pdf/2512.07814v1)

---

### [Nonlinear Quantum Mechanics and Artificial Intelligence](http://arxiv.org/abs/2512.07809v1)
**Authors:** Jonathan Oppenheim  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** hep-th, quant-ph  

**Abstract:** We examine a criterion for relativistic covariance of nonlinear quantum field theory recently proposed by GPT-5 and published in Physics Letters B. We show that this criterion inadvertently tests a different property -- locality of the Hamiltonian -- and is insensitive to whether the theory is nonlinear. We recall the correct criterion, identified by Gisin and Polchinski thirty-five years ago, and...

[View on arXiv](http://arxiv.org/abs/2512.07809v1) | [PDF](https://arxiv.org/pdf/2512.07809v1)

---

### [Group Representational Position Encoding](http://arxiv.org/abs/2512.07805v1)
**Authors:** Yifan Zhang, Zixiang Chen, Yifeng Liu et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.LG, cs.AI, cs.CL  

**Abstract:** We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a ...

[View on arXiv](http://arxiv.org/abs/2512.07805v1) | [PDF](https://arxiv.org/pdf/2512.07805v1)

---

### [Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support](http://arxiv.org/abs/2512.07801v1)
**Authors:** Raunak Jain, Mudita Khurana  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.CL, cs.AI, cs.HC, cs.LG  

**Abstract:** LLM-based agents are rapidly being plugged into expert decision-support, yet in messy, high-stakes settings they rarely make the team smarter: human-AI teams often underperform the best individual, experts oscillate between verification loops and over-reliance, and the promised complementarity does not materialise. We argue this is not just a matter of accuracy, but a fundamental gap in how we con...

[View on arXiv](http://arxiv.org/abs/2512.07801v1) | [PDF](https://arxiv.org/pdf/2512.07801v1)

---

### [Trapped Fermions Through Kolmogorov-Arnold Wavefunctions](http://arxiv.org/abs/2512.07800v1)
**Authors:** Paulo F. Bedaque, Jacob Cigliano, Hersh Kumar et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** nucl-th, cond-mat.dis-nn, cond-mat.quant-gas, physics.comp-ph, quant-ph  

**Abstract:** We investigate a variational Monte Carlo framework for trapped one-dimensional mixture of spin-$\frac{1}{2}$ fermions using Kolmogorov-Arnold networks (KANs) to construct universal neural-network wavefunction ansätze. The method can, in principle, achieve arbitrary accuracy, limited only by the Monte Carlo sampling and was checked against exact results at sub-percent precision. For attractive inte...

[View on arXiv](http://arxiv.org/abs/2512.07800v1) | [PDF](https://arxiv.org/pdf/2512.07800v1)

---

### [Large Causal Models from Large Language Models](http://arxiv.org/abs/2512.07796v1)
**Authors:** Sridhar Mahadevan  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.AI  

**Abstract:** We introduce a new paradigm for building large causal models (LCMs) that exploits the enormous potential latent in today's large language models (LLMs). We describe our ongoing experiments with an implemented system called DEMOCRITUS (Decentralized Extraction of Manifold Ontologies of Causal Relations Integrating Topos Universal Slices) aimed at building, organizing, and visualizing LCMs that span...

[View on arXiv](http://arxiv.org/abs/2512.07796v1) | [PDF](https://arxiv.org/pdf/2512.07796v1)

---

### [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](http://arxiv.org/abs/2512.07795v1)
**Authors:** Nearchos Potamitis, Lars Klein, Akhil Arora  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.AI, cs.CL, cs.LG  

**Abstract:** Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess ...

[View on arXiv](http://arxiv.org/abs/2512.07795v1) | [PDF](https://arxiv.org/pdf/2512.07795v1)

---

### [GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory](http://arxiv.org/abs/2512.07782v1)
**Authors:** Jiaxu Liu, Yuhe Bai, Christos-Savvas Bouganis  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.LG  

**Abstract:** Modern autoregressive models rely on attention, yet the Softmax full attention in Transformers scales quadratically with sequence length. Sliding Window Attention (SWA) achieves linear-time encoding/decoding by constraining the attention pattern, but under an \textit{Associative Memory} interpretation, its difference-style update renders the training objective effectively \emph{unbounded}. In cont...

[View on arXiv](http://arxiv.org/abs/2512.07782v1) | [PDF](https://arxiv.org/pdf/2512.07782v1)

---

### [Distribution-informed Online Conformal Prediction](http://arxiv.org/abs/2512.07770v1)
**Authors:** Dongjian Hu, Junxi Wu, Shu-Tao Xia et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** stat.ML, cs.LG  

**Abstract:** Conformal prediction provides a pivotal and flexible technique for uncertainty quantification by constructing prediction sets with a predefined coverage rate. Many online conformal prediction methods have been developed to address data distribution shifts in fully adversarial environments, resulting in overly conservative prediction sets. We propose Conformal Optimistic Prediction (COP), an online...

[View on arXiv](http://arxiv.org/abs/2512.07770v1) | [PDF](https://arxiv.org/pdf/2512.07770v1)

---

### [Formalized Hopfield Networks and Boltzmann Machines](http://arxiv.org/abs/2512.07766v1)
**Authors:** Matteo Cipollina, Michail Karatarakis, Freek Wiedijk  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** cs.LG, cs.LO  

**Abstract:** Neural networks are widely used, yet their analysis and verification remain challenging. In this work, we present a Lean 4 formalization of neural networks, covering both deterministic and stochastic models. We first formalize Hopfield networks, recurrent networks that store patterns as stable states. We prove convergence and the correctness of Hebbian learning, a training rule that updates networ...

[View on arXiv](http://arxiv.org/abs/2512.07766v1) | [PDF](https://arxiv.org/pdf/2512.07766v1)

---

### [Physics-Informed Neural Networks for Source Inversion and Parameters Estimation in Atmospheric Dispersion](http://arxiv.org/abs/2512.07755v1)
**Authors:** Brenda Anague, Bamdad Hosseini, Issa Karambal et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** stat.ML, cs.LG  

**Abstract:** Recent studies have shown the success of deep learning in solving forward and inverse problems in engineering and scientific computing domains, such as physics-informed neural networks (PINNs). In the fields of atmospheric science and environmental monitoring, estimating emission source locations is a central task that further relies on multiple model parameters that dictate velocity profiles and ...

[View on arXiv](http://arxiv.org/abs/2512.07755v1) | [PDF](https://arxiv.org/pdf/2512.07755v1)

---

### [Statistical properties of quantum jumps between macroscopic states of light: reading an operational coherence record](http://arxiv.org/abs/2512.07754v1)
**Authors:** Th. K. Mavrogordatos  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph, cond-mat.mes-hall, physics.optics  

**Abstract:** We propose an experimental apparatus to reveal the quantum coherence manifested in downward quantum jumps of amplitude bistability. The underlying coherent superposition of macroscopic quantum states is translated into the statistical properties of the integrated charge deposited in the detector circuit of a mode-matched heterodyne/homodyne detection scheme. At first, the dynamical evolution of a ...

[View on arXiv](http://arxiv.org/abs/2512.07754v1) | [PDF](https://arxiv.org/pdf/2512.07754v1)

---

### [Real-time collisions of fractional charges in a trapped-ion Jackiw-Rebbi field theory](http://arxiv.org/abs/2512.07748v1)
**Authors:** Alan Kahan, Pablo Viñas, Torsten V. Zache et al.  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** quant-ph  

**Abstract:** We propose and analyze a trapped-ion quantum simulator of the Jackiw-Rebbi model, a paradigmatic quantum field theory in (1+1) dimensions where solitonic excitations of a scalar field can bind fermionic zero modes leading to fractionally charged excitations. In our approach, the scalar field is a coarse-grained description of the planar zigzag ion displacements in the vicinity of a structural phas...

[View on arXiv](http://arxiv.org/abs/2512.07748v1) | [PDF](https://arxiv.org/pdf/2512.07748v1)

---

### [Grand Canonical vs Canonical Krylov Complexity in Double-Scaled Complex SYK Model](http://arxiv.org/abs/2512.07715v1)
**Authors:** Stefan Forste, Yannic Kruse, Saurabh Natu  
**Published:** 2025-12-08  
**Updated:** 2025-12-08  
**Categories:** hep-th, cond-mat.str-el, quant-ph  

**Abstract:** We consider the complex SYK model in the double-scaling limit. We obtain the transfer matrix for the grand canonical ensemble and symmetrize it. In the (n,Q)- basis of chord states, the grand canonical transfer matrix is block diagonal, where each block is the canonical transfer matrix for the respective charge sector. We therefore conclude that the Krylov complexity for the grand canonical ensemb...

[View on arXiv](http://arxiv.org/abs/2512.07715v1) | [PDF](https://arxiv.org/pdf/2512.07715v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
