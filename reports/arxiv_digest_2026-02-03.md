# arXiv Daily Digest - 2026-02-03

**Search Period:** Last 7 days  
**Papers Found:** 52

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Nonlinear light cone spreading of correlations in a triangular quantum magnet: a hard quantum simulation target](http://arxiv.org/abs/2602.02433v1)
**Authors:** A. Scheie, J. Willsher, E. A. Ghioldi et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cond-mat.str-el, quant-ph  

**Abstract:** Dynamical correlations of quantum many-body systems are typically analyzed in the momentum space and frequency basis. However, quantum simulators operate more naturally in real space, real time settings. Here we analyze the real-space time-dependent van Hove spin correlations $G(r,t)$ of the 2D triangular antiferromagnet KYbSe$_2$ as obtained from high-resolution Fourier-transformed neutron spectr...

[View on arXiv](http://arxiv.org/abs/2602.02433v1) | [PDF](https://arxiv.org/pdf/2602.02433v1)

---

### [Guaranteeing Privacy in Hybrid Quantum Learning through Theoretical Mechanisms](http://arxiv.org/abs/2602.02364v1)
**Authors:** Hoang M. Ngo, Tre' R. Jeter, Incheol Shin et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph, cs.CR  

**Abstract:** Quantum Machine Learning (QML) is becoming increasingly prevalent due to its potential to enhance classical machine learning (ML) tasks, such as classification. Although quantum noise is often viewed as a major challenge in quantum computing, it also offers a unique opportunity to enhance privacy. In particular, intrinsic quantum noise provides a natural stochastic resource that, when rigorously a...

[View on arXiv](http://arxiv.org/abs/2602.02364v1) | [PDF](https://arxiv.org/pdf/2602.02364v1)

---

### [AQER: a scalable and efficient data loader for digital quantum computers](http://arxiv.org/abs/2602.02165v1)
**Authors:** Kaining Zhang, Xinbiao Wang, Yuxuan Du et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph  

**Abstract:** Digital quantum computing promises to offer computational capabilities beyond the reach of classical systems, yet its capabilities are often challenged by scarce quantum resources. A critical bottleneck in this context is how to load classical or quantum data into quantum circuits efficiently. Approximate quantum loaders (AQLs) provide a viable solution to this problem by balancing fidelity and ci...

[View on arXiv](http://arxiv.org/abs/2602.02165v1) | [PDF](https://arxiv.org/pdf/2602.02165v1)

---

### [Age-Aware Edge-Blind Federated Learning via Over-the-Air Aggregation](http://arxiv.org/abs/2602.02469v1)
**Authors:** Ahmed M. Elshazly, Ahmed Arafa  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.IT, cs.LG, eess.SP  

**Abstract:** We study federated learning (FL) over wireless fading channels where multiple devices simultaneously send their model updates. We propose an efficient \emph{age-aware edge-blind over-the-air FL} approach that does not require channel state information (CSI) at the devices. Instead, the parameter server (PS) uses multiple antennas and applies maximum-ratio combining (MRC) based on its estimated sum...

[View on arXiv](http://arxiv.org/abs/2602.02469v1) | [PDF](https://arxiv.org/pdf/2602.02469v1)

---

### [Resolving problems with the continuum limit in coherent-state path integrals](http://arxiv.org/abs/2602.02466v1)
**Authors:** Oliwier Urbański  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph, math-ph  

**Abstract:** The paper solves the problem of continuum limit in bosonic thermal coherent-state path integrals. For this purpose, exact discrete versions of the path integral are constructed for three different orderings of the Hamiltonian: normal, anti-normal and symmetric (Weyl order). Subsequently, their different continuum versions are checked on the harmonic oscillator, to choose the symmetric ordering as ...

[View on arXiv](http://arxiv.org/abs/2602.02466v1) | [PDF](https://arxiv.org/pdf/2602.02466v1)

---

### [Active Transfer Bagging: A New Approach for Accelerated Active Learning Acquisition of Data by Combined Transfer Learning and Bagging Based Models](http://arxiv.org/abs/2602.02415v1)
**Authors:** Vivienne Pelletier, Daniel J. Rivera, Obinna Nwokonkwo et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG  

**Abstract:** Modern machine learning has achieved remarkable success on many problems, but this success often depends on the existence of large, labeled datasets. While active learning can dramatically reduce labeling cost when annotations are expensive, early performance is frequently dominated by the initial seed set, typically chosen at random. In many applications, however, related or approximate datasets ...

[View on arXiv](http://arxiv.org/abs/2602.02415v1) | [PDF](https://arxiv.org/pdf/2602.02415v1)

---

### [On the Spectral theory of Isogeny Graphs and Quantum Sampling of Hard Supersingular Elliptic curves](http://arxiv.org/abs/2602.02263v1)
**Authors:** David Jao, Maher Mamah  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph, math.NT  

**Abstract:** In this paper we study the problem of sampling random supersingular elliptic curves with unknown endomorphism rings. This task has recently attracted significant attention, as the secure instantiation of many isogeny-based cryptographic protocols relies on the ability to sample such ``hard'' curves. Existing approaches, however, achieve this only in a trusted-setup setting. We present the first pr...

[View on arXiv](http://arxiv.org/abs/2602.02263v1) | [PDF](https://arxiv.org/pdf/2602.02263v1)

---

### [Energy-Transfer-Enhanced Emission and Quantum Sensing of VB- Defects in hBN-PbI2 Heterostructures](http://arxiv.org/abs/2602.02256v1)
**Authors:** Eveline Mayner, Yaroslav Zhumagulov, Cristian de Giorgio et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cond-mat.mtrl-sci, physics.optics, quant-ph  

**Abstract:** Spin defects in two-dimensional materials hold significant potential for quantum information technologies and sensing applications. The negatively charged boron vacancy (VB-) in hexagonal boron nitride (hBN) has attracted considerable attention as a quantum sensor due to its demonstrated sensitivity to temperature, magnetic fields, and pressure.1 However, its applications have thus far been limite...

[View on arXiv](http://arxiv.org/abs/2602.02256v1) | [PDF](https://arxiv.org/pdf/2602.02256v1)

---

### [Reward-free Alignment for Conflicting Objectives](http://arxiv.org/abs/2602.02495v1)
**Authors:** Peter Chen, Xiaopeng Li, Xi Chen et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectiv...

[View on arXiv](http://arxiv.org/abs/2602.02495v1) | [PDF](https://arxiv.org/pdf/2602.02495v1)

---

### [MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](http://arxiv.org/abs/2602.02494v1)
**Authors:** Dulhan Jayalath, Oiwi Parker Jones  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, q-bio.NC  

**Abstract:** Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose...

[View on arXiv](http://arxiv.org/abs/2602.02494v1) | [PDF](https://arxiv.org/pdf/2602.02494v1)

---

### [PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](http://arxiv.org/abs/2602.02493v1)
**Authors:** Zehong Ma, Ruihan Xu, Shiliang Zhang  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.AI  

**Abstract:** Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a si...

[View on arXiv](http://arxiv.org/abs/2602.02493v1) | [PDF](https://arxiv.org/pdf/2602.02493v1)

---

### [RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System](http://arxiv.org/abs/2602.02488v1)
**Authors:** Yinjie Wang, Tianbao Xie, Ke Shen et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, cs.CL  

**Abstract:** We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized vi...

[View on arXiv](http://arxiv.org/abs/2602.02488v1) | [PDF](https://arxiv.org/pdf/2602.02488v1)

---

### [RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents](http://arxiv.org/abs/2602.02486v1)
**Authors:** Jialiang Zhu, Gongrui Zhang, Xiaolong Ma et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CL, cs.AI  

**Abstract:** LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by gene...

[View on arXiv](http://arxiv.org/abs/2602.02486v1) | [PDF](https://arxiv.org/pdf/2602.02486v1)

---

### [Expanding the Capabilities of Reinforcement Learning via Text Feedback](http://arxiv.org/abs/2602.02482v1)
**Authors:** Yuda Song, Lili Chen, Fahim Tajwar et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG  

**Abstract:** The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete...

[View on arXiv](http://arxiv.org/abs/2602.02482v1) | [PDF](https://arxiv.org/pdf/2602.02482v1)

---

### [Flow Policy Gradients for Robot Control](http://arxiv.org/abs/2602.02481v1)
**Authors:** Brent Yi, Hongsuk Choi, Himanshu Gaurav Singh et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.RO, cs.AI  

**Abstract:** Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training a...

[View on arXiv](http://arxiv.org/abs/2602.02481v1) | [PDF](https://arxiv.org/pdf/2602.02481v1)

---

### [AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](http://arxiv.org/abs/2602.02475v1)
**Authors:** Shraddha Barke, Arnav Goyal, Alind Khare et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI  

**Abstract:** AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with ...

[View on arXiv](http://arxiv.org/abs/2602.02475v1) | [PDF](https://arxiv.org/pdf/2602.02475v1)

---

### [MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](http://arxiv.org/abs/2602.02474v1)
**Authors:** Haozhen Zhang, Quanyu Long, Jianzhu Bao et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable ...

[View on arXiv](http://arxiv.org/abs/2602.02474v1) | [PDF](https://arxiv.org/pdf/2602.02474v1)

---

### [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](http://arxiv.org/abs/2602.02473v1)
**Authors:** Yinhuai Wang, Qihan Zhao, Yuen Fui Lau et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.RO, cs.LG  

**Abstract:** Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into general...

[View on arXiv](http://arxiv.org/abs/2602.02473v1) | [PDF](https://arxiv.org/pdf/2602.02473v1)

---

### [SPARKLING: Balancing Signal Preservation and Symmetry Breaking for Width-Progressive Learning](http://arxiv.org/abs/2602.02472v1)
**Authors:** Qifan Yu, Xinyu Ma, Zhijian Zhuo et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, cs.CL  

**Abstract:** Progressive Learning (PL) reduces pre-training computational overhead by gradually increasing model scale. While prior work has extensively explored depth expansion, width expansion remains significantly understudied, with the few existing methods limited to the early stages of training. However, expanding width during the mid-stage is essential for maximizing computational savings, yet it remains...

[View on arXiv](http://arxiv.org/abs/2602.02472v1) | [PDF](https://arxiv.org/pdf/2602.02472v1)

---

### [Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](http://arxiv.org/abs/2602.02471v1)
**Authors:** Edwin Kys, Febian Febian  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.AI, physics.med-ph  

**Abstract:** Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level...

[View on arXiv](http://arxiv.org/abs/2602.02471v1) | [PDF](https://arxiv.org/pdf/2602.02471v1)

---

### [Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge](http://arxiv.org/abs/2602.02470v1)
**Authors:** Xutao Ma, Yixiao Huang, Hanlin Zhu et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI  

**Abstract:** Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the "reversal curse" -- when trained on forward knowledge data of the form "$A \rightarrow B$" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge "$B \leftarrow A$" (e.g., Bob's wife is Alice) during t...

[View on arXiv](http://arxiv.org/abs/2602.02470v1) | [PDF](https://arxiv.org/pdf/2602.02470v1)

---

### [MentisOculi: Revealing the Limits of Reasoning with Mental Imagery](http://arxiv.org/abs/2602.02465v1)
**Authors:** Jana Zeller, Thaddäus Wiedemer, Fanfei Li et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI, cs.CV, cs.LG  

**Abstract:** Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual represen...

[View on arXiv](http://arxiv.org/abs/2602.02465v1) | [PDF](https://arxiv.org/pdf/2602.02465v1)

---

### [Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models](http://arxiv.org/abs/2602.02462v1)
**Authors:** Gabriele Maraia, Marco Valentino, Fabio Massimo Zanzotto et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CL, cs.AI  

**Abstract:** Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mit...

[View on arXiv](http://arxiv.org/abs/2602.02462v1) | [PDF](https://arxiv.org/pdf/2602.02462v1)

---

### [Conflict-Aware Client Selection for Multi-Server Federated Learning](http://arxiv.org/abs/2602.02458v1)
**Authors:** Mingwei Hong, Zheng Lin, Zehang Lin et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, cs.NI  

**Abstract:** Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While m...

[View on arXiv](http://arxiv.org/abs/2602.02458v1) | [PDF](https://arxiv.org/pdf/2602.02458v1)

---

### [Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](http://arxiv.org/abs/2602.02455v1)
**Authors:** Han Bao, Zheyuan Zhang, Pengcheng Jing et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI, cs.CL, cs.SE  

**Abstract:** As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarificati...

[View on arXiv](http://arxiv.org/abs/2602.02455v1) | [PDF](https://arxiv.org/pdf/2602.02455v1)

---

### [World-Gymnast: Training Robots with Reinforcement Learning in a World Model](http://arxiv.org/abs/2602.02454v1)
**Authors:** Ansh Kumar Sharma, Yixiang Sun, Ninghao Lu et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.RO, cs.AI  

**Abstract:** Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models le...

[View on arXiv](http://arxiv.org/abs/2602.02454v1) | [PDF](https://arxiv.org/pdf/2602.02454v1)

---

### [Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling](http://arxiv.org/abs/2602.02453v1)
**Authors:** Andong Chen, Wenxin Zhu, Qiuyu Ding et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI  

**Abstract:** Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses...

[View on arXiv](http://arxiv.org/abs/2602.02453v1) | [PDF](https://arxiv.org/pdf/2602.02453v1)

---

### [Active Causal Experimentalist (ACE): Learning Intervention Strategies via Direct Preference Optimization](http://arxiv.org/abs/2602.02451v1)
**Authors:** Patrick Cooper, Alvaro Velasquez  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, cs.AI  

**Abstract:** Discovering causal relationships requires controlled experiments, but experimentalists face a sequential decision problem: each intervention reveals information that should inform what to try next. Traditional approaches such as random sampling, greedy information maximization, and round-robin coverage treat each decision in isolation, unable to learn adaptive strategies from experience. We propos...

[View on arXiv](http://arxiv.org/abs/2602.02451v1) | [PDF](https://arxiv.org/pdf/2602.02451v1)

---

### [Finite-Sample Wasserstein Error Bounds and Concentration Inequalities for Nonlinear Stochastic Approximation](http://arxiv.org/abs/2602.02445v1)
**Authors:** Seo Taek Kong, R. Srikant  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, math.ST  

**Abstract:** This paper derives non-asymptotic error bounds for nonlinear stochastic approximation algorithms in the Wasserstein-$p$ distance. To obtain explicit finite-sample guarantees for the last iterate, we develop a coupling argument that compares the discrete-time process to a limiting Ornstein-Uhlenbeck process. Our analysis applies to algorithms driven by general noise conditions, including martingale...

[View on arXiv](http://arxiv.org/abs/2602.02445v1) | [PDF](https://arxiv.org/pdf/2602.02445v1)

---

### [Certain Head, Uncertain Tail: Expert-Sample for Test-Time Scaling in Fine-Grained MoE](http://arxiv.org/abs/2602.02443v1)
**Authors:** Yuanteng Chen, Peisong Wang, Nanxin Zeng et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG  

**Abstract:** Test-time scaling improves LLM performance by generating multiple candidate solutions, yet token-level sampling requires temperature tuning that trades off diversity against stability. Fine-grained MoE, featuring hundreds of well-trained experts per layer and multi-expert activation per token, offers an unexplored alternative through its rich routing space. We empirically characterize fine-grained...

[View on arXiv](http://arxiv.org/abs/2602.02443v1) | [PDF](https://arxiv.org/pdf/2602.02443v1)

---

### [Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization](http://arxiv.org/abs/2602.02439v1)
**Authors:** Olaf Yunus Laitinen Imanov, Derya Umut Kulali, Taner Yilmaz et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.NE, cs.ET, cs.LG  

**Abstract:** Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SN...

[View on arXiv](http://arxiv.org/abs/2602.02439v1) | [PDF](https://arxiv.org/pdf/2602.02439v1)

---

### [Maximizing Reliability with Bayesian Optimization](http://arxiv.org/abs/2602.02432v1)
**Authors:** Jack M. Buckingham, Ivo Couckuyt, Juergen Branke  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, math.OC, stat.ML  

**Abstract:** Bayesian optimization (BO) is a popular, sample-efficient technique for expensive, black-box optimization. One such problem arising in manufacturing is that of maximizing the reliability, or equivalently minimizing the probability of a failure, of a design which is subject to random perturbations - a problem that can involve extremely rare failures ($P_\mathrm{fail} = 10^{-6}-10^{-8}$). In this wo...

[View on arXiv](http://arxiv.org/abs/2602.02432v1) | [PDF](https://arxiv.org/pdf/2602.02432v1)

---

### [Full-Batch Gradient Descent Outperforms One-Pass SGD: Sample Complexity Separation in Single-Index Learning](http://arxiv.org/abs/2602.02431v1)
**Authors:** Filip Kovačević, Hong Chang Ji, Denny Wu et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** stat.ML, cs.LG  

**Abstract:** It is folklore that reusing training data more than once can improve the statistical efficiency of gradient-based learning. However, beyond linear regression, the theoretical advantage of full-batch gradient descent (GD, which always reuses all the data) over one-pass stochastic gradient descent (online SGD, which uses each data point only once) remains unclear. In this work, we consider learning ...

[View on arXiv](http://arxiv.org/abs/2602.02431v1) | [PDF](https://arxiv.org/pdf/2602.02431v1)

---

### [Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning](http://arxiv.org/abs/2602.02427v1)
**Authors:** Qihao Wen, Jiahao Wang, Yang Nan et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG  

**Abstract:** Large language Models (LLMs) have achieved significant breakthroughs across diverse domains; however, they can still produce unreliable or misleading outputs. For responsible LLM application, Uncertainty Quantification (UQ) techniques are used to estimate a model's uncertainty about its outputs, indicating the likelihood that those outputs may be problematic. For LLM reasoning tasks, it is essenti...

[View on arXiv](http://arxiv.org/abs/2602.02427v1) | [PDF](https://arxiv.org/pdf/2602.02427v1)

---

### [Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization](http://arxiv.org/abs/2602.02425v1)
**Authors:** Amaru Caceres Arroyo, Lea Bogensperger, Ahmed Allam et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, q-bio.QM  

**Abstract:** Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space...

[View on arXiv](http://arxiv.org/abs/2602.02425v1) | [PDF](https://arxiv.org/pdf/2602.02425v1)

---

### [Poly-attention: a general scheme for higher-order self-attention](http://arxiv.org/abs/2602.02422v1)
**Authors:** Sayak Chakrabarti, Toniann Pitassi, Josh Alman  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG, cs.AI  

**Abstract:** The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives...

[View on arXiv](http://arxiv.org/abs/2602.02422v1) | [PDF](https://arxiv.org/pdf/2602.02422v1)

---

### [Masked Autoencoders as Universal Speech Enhancer](http://arxiv.org/abs/2602.02413v1)
**Authors:** Rajalaxmi Rajagopalan, Ritwik Giri, Zhiqiang Tang et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.SD, cs.LG  

**Abstract:** Supervised speech enhancement methods have been very successful. However, in practical scenarios, there is a lack of clean speech, and self-supervised learning-based (SSL) speech enhancement methods that offer comparable enhancement performance and can be applied to other speech-related downstream applications are desired. In this work, we develop a masked autoencoder based universal speech enhanc...

[View on arXiv](http://arxiv.org/abs/2602.02413v1) | [PDF](https://arxiv.org/pdf/2602.02413v1)

---

### [ReasonEdit: Editing Vision-Language Models using Human Reasoning](http://arxiv.org/abs/2602.02408v1)
**Authors:** Jiaxing Qiu, Kaihua Hou, Roxana Daneshjou et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.AI  

**Abstract:** Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introduc...

[View on arXiv](http://arxiv.org/abs/2602.02408v1) | [PDF](https://arxiv.org/pdf/2602.02408v1)

---

### [Provably Data-driven Multiple Hyper-parameter Tuning with Structured Loss Function](http://arxiv.org/abs/2602.02406v1)
**Authors:** Tung Quoc Le, Anh Tuan Nguyen, Viet Anh Nguyen  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** stat.ML, cs.LG  

**Abstract:** Data-driven algorithm design automates hyperparameter tuning, but its statistical foundations remain limited because model performance can depend on hyperparameters in implicit and highly non-smooth ways. Existing guarantees focus on the simple case of a one-dimensional (scalar) hyperparameter. This leaves the practically important, multi-dimensional hyperparameter tuning setting unresolved. We ad...

[View on arXiv](http://arxiv.org/abs/2602.02406v1) | [PDF](https://arxiv.org/pdf/2602.02406v1)

---

### [SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation](http://arxiv.org/abs/2602.02402v1)
**Authors:** Mu Huang, Hui Wang, Kerui Ren et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.RO, cs.AI, cs.CV, physics.app-ph  

**Abstract:** Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat sim...

[View on arXiv](http://arxiv.org/abs/2602.02402v1) | [PDF](https://arxiv.org/pdf/2602.02402v1)

---

### [Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing](http://arxiv.org/abs/2602.02386v1)
**Authors:** Mika Okamoto, Ansel Kaplan Erol, Glenn Matlin  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.AI, cs.IR, cs.LG  

**Abstract:** How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requ...

[View on arXiv](http://arxiv.org/abs/2602.02386v1) | [PDF](https://arxiv.org/pdf/2602.02386v1)

---

### [Self-Supervised Learning from Structural Invariance](http://arxiv.org/abs/2602.02381v1)
**Authors:** Yipeng Zhang, Hafez Ghaemi, Jungyoon Lee et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.LG  

**Abstract:** Joint-embedding self-supervised learning (SSL), the key paradigm for unsupervised representation learning from visual data, learns from invariances between semantically-related data pairs. We study the one-to-many mapping problem in SSL, where each datum may be mapped to multiple valid targets. This arises when data pairs come from naturally occurring generative processes, e.g., successive video f...

[View on arXiv](http://arxiv.org/abs/2602.02381v1) | [PDF](https://arxiv.org/pdf/2602.02381v1)

---

### [NAB: Neural Adaptive Binning for Sparse-View CT reconstruction](http://arxiv.org/abs/2602.02356v1)
**Authors:** Wangduo Xie, Matthew B. Blaschko  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.LG  

**Abstract:** Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation th...

[View on arXiv](http://arxiv.org/abs/2602.02356v1) | [PDF](https://arxiv.org/pdf/2602.02356v1)

---

### [Implicit neural representation of textures](http://arxiv.org/abs/2602.02354v1)
**Authors:** Albert Kwok, Zheyuan Hu, Dounia Hammou  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.AI, cs.GR, cs.LG  

**Abstract:** Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with con...

[View on arXiv](http://arxiv.org/abs/2602.02354v1) | [PDF](https://arxiv.org/pdf/2602.02354v1)

---

### [Artificial Intelligence and Symmetries: Learning, Encoding, and Discovering Structure in Physical Data](http://arxiv.org/abs/2602.02351v1)
**Authors:** Veronica Sanz  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** hep-ph, cs.AI, cs.LG  

**Abstract:** Symmetries play a central role in physics, organizing dynamics, constraining interactions, and determining the effective number of physical degrees of freedom. In parallel, modern artificial intelligence methods have demonstrated a remarkable ability to extract low-dimensional structure from high-dimensional data through representation learning. This review examines the interplay between these two...

[View on arXiv](http://arxiv.org/abs/2602.02351v1) | [PDF](https://arxiv.org/pdf/2602.02351v1)

---

### [Large Nc Truncations for SU(Nc) Lattice Yang-Mills Theory with Fermions](http://arxiv.org/abs/2602.02344v1)
**Authors:** Neel S. Modi, Anthony N. Ciavarella, Jad C. Halimeh et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** hep-lat, hep-ph, quant-ph  

**Abstract:** Quantum simulations of quantum chromodynamics (QCD) require a representation of gauge fields and fermions on the finitely many degrees of freedom available on a quantum computer. We introduce a truncation of lattice QCD coupled to staggered fermions that includes (i) a local Krylov truncation that generates allowed basis states; (ii) a maximum allowed electric energy per link; (iii) a limit on the...

[View on arXiv](http://arxiv.org/abs/2602.02344v1) | [PDF](https://arxiv.org/pdf/2602.02344v1)

---

### [VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations](http://arxiv.org/abs/2602.02334v1)
**Authors:** Fatemeh Zargarbashi, Dhruv Agrawal, Jakob Buhmann et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cs.CV, cs.AI, cs.LG  

**Abstract:** Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, e...

[View on arXiv](http://arxiv.org/abs/2602.02334v1) | [PDF](https://arxiv.org/pdf/2602.02334v1)

---

### [Optimal enhancement of the Overhauser and Solid Effects within a unified framework](http://arxiv.org/abs/2602.02309v1)
**Authors:** Sarfraj Fency, Rangeet Bhattacharyya  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph  

**Abstract:** The Overhauser effect (OE) and the Solid effect (SE) are two Dynamic Nuclear Polarization techniques. These two-spin techniques are widely used to create nonequilibrium nuclear spin states having polarization far beyond its equilibrium value. OE is commonly encountered in liquids, and SE is a solid-state technique. Here, we report a single framework based on a recently proposed quantum master equa...

[View on arXiv](http://arxiv.org/abs/2602.02309v1) | [PDF](https://arxiv.org/pdf/2602.02309v1)

---

### [Non-Perturbative SDiff Covariance of Fractional Quantum Hall Excitations](http://arxiv.org/abs/2602.02292v1)
**Authors:** Hisham Sati, Urs Schreiber  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cond-mat.str-el, hep-th, math-ph, quant-ph  

**Abstract:** Collective excitations of Fractional Quantum Hall (FQH) liquids at long wavelengths are thought to be of a generally covariant geometric nature, governed by area-preserving diffeomorphisms ($\mathrm{SDiff}$). But current analyses rely solely on the corresponding perturbative $w_\infty$ Lie algebra. We argue this is insufficient: We identify a non-perturbative construction of the effective Maxwell-...

[View on arXiv](http://arxiv.org/abs/2602.02292v1) | [PDF](https://arxiv.org/pdf/2602.02292v1)

---

### [Observing weakly broken conservation laws in a dipolar Rydberg quantum spin chain](http://arxiv.org/abs/2602.02251v1)
**Authors:** Cheng Chen, Luca Capizzi, Alice Marché et al.  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** cond-mat.quant-gas, cond-mat.stat-mech, quant-ph  

**Abstract:** Integrable quantum many-body systems host families of extensive conservation laws, some of which are fragile: even infinitesimal perturbations can qualitatively alter their dynamical constraints. Here we show that this fragility leaves a clear experimental fingerprint in a one-dimensional quantum spin chain of as few as 14 Rydberg atoms. Weak integrability breaking from interatomic dipolar couplin...

[View on arXiv](http://arxiv.org/abs/2602.02251v1) | [PDF](https://arxiv.org/pdf/2602.02251v1)

---

### [Sampling two-dimensional isometric tensor network states](http://arxiv.org/abs/2602.02245v1)
**Authors:** Alec Dektor, Eugene Dumitrescu, Chao Yang  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph, physics.comp-ph  

**Abstract:** Sampling a quantum systems underlying probability distributions is an important computational task, e.g., for quantum advantage experiments and quantum Monte Carlo algorithms. Tensor networks are an invaluable tool for efficiently representing states of large quantum systems with limited entanglement. Algorithms for sampling one-dimensional (1D) tensor networks are well-established and utilized in...

[View on arXiv](http://arxiv.org/abs/2602.02245v1) | [PDF](https://arxiv.org/pdf/2602.02245v1)

---

### [The trouble with recording devices](http://arxiv.org/abs/2602.02191v1)
**Authors:** Eric Tesse  
**Published:** 2026-02-02  
**Updated:** 2026-02-02  
**Categories:** quant-ph  

**Abstract:** Quantum theory encounters a difficulty when attempting to describe recording devices. If the recording is of events in which quantum uncertainty plays a role, such as an experiment on a quantum system, quantum theory is unable to correctly predict the probabilities of both future and past states of the recording. The nature of this difficulty will be laid out at the outset. A resolution then will ...

[View on arXiv](http://arxiv.org/abs/2602.02191v1) | [PDF](https://arxiv.org/pdf/2602.02191v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
