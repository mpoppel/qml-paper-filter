# arXiv Daily Digest - 2025-12-24

**Search Period:** Last 7 days  
**Papers Found:** 24

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Experimental characterization of the Toffoli gate via channel spectrum benchmarking](http://arxiv.org/abs/2512.20545v1)
**Authors:** D. K. Korliakov, B. I. Bantysh, A. S. Borisenko et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph  

**Abstract:** Channel spectrum benchmarking (CSB) provides a robust framework for characterizing quantum gate fidelities while remaining insensitive to state preparation and measurement (SPAM) errors. Yet, current CSB implementations encounter fundamental challenges when reconstructing noisy eigenvalues, particularly in the presence of spectral degeneracies and off-diagonal noise components in the target gate's...

[View on arXiv](http://arxiv.org/abs/2512.20545v1) | [PDF](https://arxiv.org/pdf/2512.20545v1)

---

### [Tunably realizing flat-bands and exceptional points in kinetically frustrated systems: An example on the non-Hermitian Creutz ladder](http://arxiv.org/abs/2512.20614v1)
**Authors:** Debashish Dutta, Sayan Choudhury  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, cond-mat.quant-gas, cond-mat.stat-mech  

**Abstract:** We study a non-Hermitian extension of the Creutz ladder with generic non-reciprocal hopping. By mapping the ladder onto two decoupled non-Hermitian Su--Schrieffer--Heeger (SSH) chains, we uncover a rich structure in parameter space under different boundary conditions. Under periodic boundary conditions, the spectrum admits a fine-tuned line in parameter space with entirely real eigenvalues, while ...

[View on arXiv](http://arxiv.org/abs/2512.20614v1) | [PDF](https://arxiv.org/pdf/2512.20614v1)

---

### [Quantum Gates from Wolfram Model Multiway Rewriting Systems](http://arxiv.org/abs/2512.20587v1)
**Authors:** Furkan Semih Dündar, Xerxes D. Arsiwalla, Hatem Elshatlawy  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, cs.DM, math-ph, math.QA  

**Abstract:** We show how representations of finite-dimensional quantum operators can be constructed using nondeterministic rewriting systems. In particular, we investigate Wolfram model multiway rewriting systems based on string substitutions. Multiway systems were proposed by S. Wolfram as generic model systems for multicomputational processes, emphasizing their significance as a foundation for modeling compl...

[View on arXiv](http://arxiv.org/abs/2512.20587v1) | [PDF](https://arxiv.org/pdf/2512.20587v1)

---

### [Variational (matrix) product states for combinatorial optimization](http://arxiv.org/abs/2512.20613v1)
**Authors:** Guillermo Preisser, Conor Mc Keever, Michael Lubasch  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, physics.comp-ph  

**Abstract:** To compute approximate solutions for combinatorial optimization problems, we describe variational methods based on the product state (PS) and matrix product state (MPS) ansatzes. We perform variational energy minimization with respect to a quantum annealing Hamiltonian and utilize randomness by embedding the approaches in the metaheuristic iterated local search (ILS). The resulting quantum-inspire...

[View on arXiv](http://arxiv.org/abs/2512.20613v1) | [PDF](https://arxiv.org/pdf/2512.20613v1)

---

### [Quantum State Preparation via Schmidt Spectrum Optimisation](http://arxiv.org/abs/2512.20537v1)
**Authors:** Josh Green, Joshua Snow, Jingbo B Wang  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph  

**Abstract:** We introduce an efficient algorithm for the systematic design of shallow-depth quantum circuits capable of preparing many-body quantum states represented as Matrix Product States (MPS). The proposed method leverages Schmidt spectrum optimization (SSO) to minimize circuit depth while preserving the entanglement structure inherent to MPS representations, thereby enabling scalable state preparation o...

[View on arXiv](http://arxiv.org/abs/2512.20537v1) | [PDF](https://arxiv.org/pdf/2512.20537v1)

---

### [LongVideoAgent: Multi-Agent Reasoning with Long Videos](http://arxiv.org/abs/2512.20618v1)
**Authors:** Runtao Liu, Ziyi Liu, Jiaqi Tang et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.AI, cs.CV, cs.LG, cs.MA  

**Abstract:** Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize questio...

[View on arXiv](http://arxiv.org/abs/2512.20618v1) | [PDF](https://arxiv.org/pdf/2512.20618v1)

---

### [Single-LED-pumped, room-temperature, solid-state maser](http://arxiv.org/abs/2512.20611v1)
**Authors:** Michael Newns, Shirley Xu, Mingyang Liu et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph  

**Abstract:** Through their ability to achieve `cryogenic' levels of noise performance while operating at room temperature, optically-pumped, solid-state (OPSS) masers show great promise as quantum sensors, oscillators, and amplifiers. We here demonstrate maser oscillation in a microwave cavity containing a crystal of pentacene-doped \textit{para}-terphenyl (ptc:ptp) pumped by a single, chip-scale LED. Here, un...

[View on arXiv](http://arxiv.org/abs/2512.20611v1) | [PDF](https://arxiv.org/pdf/2512.20611v1)

---

### [FedPOD: the deployable units of training for federated learning](http://arxiv.org/abs/2512.20610v1)
**Authors:** Daewoon Kim, Si Young Yie, Jae Sung Lee  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.CV, cs.LG  

**Abstract:** This paper proposes FedPOD (Proportionally Orchestrated Derivative) for optimizing learning efficiency and communication cost in federated learning among multiple clients. Inspired by FedPIDAvg, we define a round-wise task for FedPOD to enhance training efficiency. FedPIDAvg achieved performance improvement by incorporating the training loss reduction for prediction entropy as weights using differ...

[View on arXiv](http://arxiv.org/abs/2512.20610v1) | [PDF](https://arxiv.org/pdf/2512.20610v1)

---

### [Rényi-like entanglement probe of the chiral central charge](http://arxiv.org/abs/2512.20608v1)
**Authors:** Julian Gass, Michael Levin  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cond-mat.str-el, quant-ph  

**Abstract:** We propose a ground state entanglement probe for gapped, two-dimensional quantum many-body systems that involves taking powers of reduced density matrices in a particular geometric configuration. This quantity, which we denote by $ω_{α,β}$, is parameterized by two positive real numbers $α, β$, and can be seen as a ``Rényi-like" generalization of the modular commutator -- another entanglement probe...

[View on arXiv](http://arxiv.org/abs/2512.20608v1) | [PDF](https://arxiv.org/pdf/2512.20608v1)

---

### [Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures](http://arxiv.org/abs/2512.20607v1)
**Authors:** Yedi Zhang, Andrew Saxe, Peter E. Latham  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG  

**Abstract:** Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explains a simplicity bias arising from saddle-to-saddle learning dynamics for a general class of neural n...

[View on arXiv](http://arxiv.org/abs/2512.20607v1) | [PDF](https://arxiv.org/pdf/2512.20607v1)

---

### [Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning](http://arxiv.org/abs/2512.20605v1)
**Authors:** Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG, cs.AI  

**Abstract:** Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that i...

[View on arXiv](http://arxiv.org/abs/2512.20605v1) | [PDF](https://arxiv.org/pdf/2512.20605v1)

---

### [Coexistence of distinct Discrete Time-Crystalline orders in the Floquet Lipkin-Meshkov-Glick model](http://arxiv.org/abs/2512.20603v1)
**Authors:** Shashank Mishra, Sayan Choudhury  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, cond-mat.quant-gas, cond-mat.stat-mech  

**Abstract:** We examine the distinct discrete time crystals (DTCs) that emerge in the Lipkin-Meshkov-Glick model, subjected to spatially nonuniform periodic driving. Intriguingly, we demonstrate that by appropriately tailoring the drive protocol, distinct DTC orders can be realized in different spatial regions of the system. Consequently, the system exhibits spatially varying sub-harmonic responses with distin...

[View on arXiv](http://arxiv.org/abs/2512.20603v1) | [PDF](https://arxiv.org/pdf/2512.20603v1)

---

### [Random Stinespring superchannel: converting channel queries into dilation isometry queries](http://arxiv.org/abs/2512.20599v1)
**Authors:** Filippo Girardi, Francesco Anna Mele, Haimeng Zhao et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, cond-mat.other, math-ph  

**Abstract:** The recently introduced random purification channel, which converts $n$ copies of an arbitrary mixed quantum state into $n$ copies of the same uniformly random purification, has emerged as a powerful tool in quantum information theory. Motivated by this development, we introduce a channel-level analogue, which we call the random Stinespring superchannel. This consists in a procedure to transform $...

[View on arXiv](http://arxiv.org/abs/2512.20599v1) | [PDF](https://arxiv.org/pdf/2512.20599v1)

---

### [Certified Lower Bounds and Efficient Estimation of Minimum Accuracy in Quantum Kernel Methods](http://arxiv.org/abs/2512.20588v1)
**Authors:** Demerson N. Gonçalves, Tharso D. Fernandes, Andrias M. M. Cordeiro et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph, cs.DS  

**Abstract:** The minimum accuracy heuristic evaluates quantum feature maps without requiring full quantum support vector machine (QSVM) training. However, the original formulation is computationally expensive, restricted to balanced datasets, and lacks theoretical backing. This work generalizes the metric to arbitrary binary datasets and formally proves it constitutes a certified lower bound on the optimal emp...

[View on arXiv](http://arxiv.org/abs/2512.20588v1) | [PDF](https://arxiv.org/pdf/2512.20588v1)

---

### [Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent](http://arxiv.org/abs/2512.20586v1)
**Authors:** Humza Nusrat, Luke Francisco, Bing Luo et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.AI, cs.CL, cs.HC  

**Abstract:** Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expe...

[View on arXiv](http://arxiv.org/abs/2512.20586v1) | [PDF](https://arxiv.org/pdf/2512.20586v1)

---

### [Relu and softplus neural nets as zero-sum turn-based games](http://arxiv.org/abs/2512.20582v1)
**Authors:** Stephane Gaubert, Yiannis Vlassopoulos  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG, cs.GT, math.OC  

**Abstract:** We show that the output of a ReLU neural network can be interpreted as the value of a zero-sum, turn-based, stopping game, which we call the ReLU net game. The game runs in the direction opposite to that of the network, and the input of the network serves as the terminal reward of the game. In fact, evaluating the network is the same as running the Shapley-Bellman backward recursion for the value ...

[View on arXiv](http://arxiv.org/abs/2512.20582v1) | [PDF](https://arxiv.org/pdf/2512.20582v1)

---

### [Improving ML Training Data with Gold-Standard Quality Metrics](http://arxiv.org/abs/2512.20577v1)
**Authors:** Leslie Barrett, Michael W. Sherman  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG  

**Abstract:** Hand-tagged training data is essential to many machine learning tasks. However, training data quality control has received little attention in the literature, despite data quality varying considerably with the tagging exercise. We propose methods to evaluate and enhance the quality of hand-tagged training data using statistical approaches to measure tagging consistency and agreement. We show that ...

[View on arXiv](http://arxiv.org/abs/2512.20577v1) | [PDF](https://arxiv.org/pdf/2512.20577v1)

---

### [Performative Policy Gradient: Optimality in Performative Reinforcement Learning](http://arxiv.org/abs/2512.20576v1)
**Authors:** Debabrota Basu, Udvas Das, Brahim Driss et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG, cs.AI, math.OC  

**Abstract:** Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterpart...

[View on arXiv](http://arxiv.org/abs/2512.20576v1) | [PDF](https://arxiv.org/pdf/2512.20576v1)

---

### [Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs](http://arxiv.org/abs/2512.20573v1)
**Authors:** Rui Pan, Zhuofu Chen, Ravi Netravali  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.LG, cs.AI, cs.DC  

**Abstract:** Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers t...

[View on arXiv](http://arxiv.org/abs/2512.20573v1) | [PDF](https://arxiv.org/pdf/2512.20573v1)

---

### [Distilling to Hybrid Attention Models via KL-Guided Layer Selection](http://arxiv.org/abs/2512.20569v1)
**Authors:** Yanhong Li, Songlin Yang, Shawn Tan et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.CL, cs.AI  

**Abstract:** Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention var...

[View on arXiv](http://arxiv.org/abs/2512.20569v1) | [PDF](https://arxiv.org/pdf/2512.20569v1)

---

### [Classification using quantum kernels in a radial basis function network](http://arxiv.org/abs/2512.20567v1)
**Authors:** Emily Micklethwaite, Adam Lowe  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph  

**Abstract:** Radial basis function (RBF) networks are expanded to incorporate quantum kernel functions enabling a new type of hybrid quantum-classical machine learning algorithm. Using this approach, synthetic examples are introduced which allow for proof of concept on interpolation and classification applications. Quantum kernels have primarily been applied to support vector machines (SVMs), however the quant...

[View on arXiv](http://arxiv.org/abs/2512.20567v1) | [PDF](https://arxiv.org/pdf/2512.20567v1)

---

### [LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving](http://arxiv.org/abs/2512.20563v1)
**Authors:** Long Nguyen, Micha Fauth, Bernhard Jaeger et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** cs.CV, cs.AI, cs.LG, cs.RO  

**Abstract:** Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly high...

[View on arXiv](http://arxiv.org/abs/2512.20563v1) | [PDF](https://arxiv.org/pdf/2512.20563v1)

---

### [Shallow Neural Networks Learn Low-Degree Spherical Polynomials with Learnable Channel Attention](http://arxiv.org/abs/2512.20562v1)
**Authors:** Yingzhen Yang  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** stat.ML, cs.LG, math.OC  

**Abstract:** We study the problem of learning a low-degree spherical polynomial of degree $\ell_0 = Θ(1) \ge 1$ defined on the unit sphere in $\RR^d$ by training an over-parameterized two-layer neural network (NN) with channel attention in this paper. Our main result is the significantly improved sample complexity for learning such low-degree polynomials. We show that, for any regression risk $\eps \in (0,1)$,...

[View on arXiv](http://arxiv.org/abs/2512.20562v1) | [PDF](https://arxiv.org/pdf/2512.20562v1)

---

### [Hardware-aware and Resource-efficient Circuit Packing and Scheduling on Trapped-Ion Quantum Computers](http://arxiv.org/abs/2512.20554v1)
**Authors:** Miguel Palma, Shuwen Kan, Wenqi Wei et al.  
**Published:** 2025-12-23  
**Updated:** 2025-12-23  
**Categories:** quant-ph  

**Abstract:** The rapid expansion of quantum cloud services has led to long job queues due to single-tenant execution models that underutilize hardware resources. Quantum multi-programming (QMP) mitigates this by executing multiple circuits in parallel on a single device, but existing methods target superconducting systems with limited connectivity, high crosstalk, and lower gate fidelity. Trapped-ion architect...

[View on arXiv](http://arxiv.org/abs/2512.20554v1) | [PDF](https://arxiv.org/pdf/2512.20554v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
