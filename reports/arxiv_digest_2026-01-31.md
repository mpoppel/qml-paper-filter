# arXiv Daily Digest - 2026-01-31

**Search Period:** Last 7 days  
**Papers Found:** 45

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Machine learning with minimal use of quantum computers: Provable advantages in Learning Under Quantum Privileged Information (LUQPI)](http://arxiv.org/abs/2601.22006v1)
**Authors:** Vasily Bokov, Lisa Kohl, Sebastian Schmitt et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph  

**Abstract:** Quantum machine learning (QML) is often listed as a promising candidate for useful applications of quantum computers, in part due to numerous proofs of possible quantum advantages. A central question is how small a role quantum computers can play while still enabling provable learning advantages over classical methods. We study an especially restricted setting in which a quantum computer is used o...

[View on arXiv](http://arxiv.org/abs/2601.22006v1) | [PDF](https://arxiv.org/pdf/2601.22006v1)

---

### [PRISM: Distribution-free Adaptive Computation of Matrix Functions for Accelerating Neural Network Training](http://arxiv.org/abs/2601.22137v1)
**Authors:** Shenghao Yang, Zhichao Wang, Oleg Balabanov et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.AI, math.NA, math.OC  

**Abstract:** Matrix functions such as square root, inverse roots, and orthogonalization play a central role in preconditioned gradient methods for neural network training. This has motivated the development of iterative algorithms that avoid explicit eigendecompositions and rely primarily on matrix multiplications, making them well suited for modern GPU accelerators. We present PRISM (Polynomial-fitting and Ra...

[View on arXiv](http://arxiv.org/abs/2601.22137v1) | [PDF](https://arxiv.org/pdf/2601.22137v1)

---

### [A scalable quantum-enhanced greedy algorithm for maximum independent set problems](http://arxiv.org/abs/2601.21923v1)
**Authors:** Elisabeth Wybo, Jami Rönkkö, Olli Hirviniemi et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph  

**Abstract:** We investigate a hybrid quantum-classical algorithm for solving the Maximum Independent Set (MIS) problem on regular graphs, combining the Quantum Approximate Optimization Algorithm (QAOA) with a minimal degree classical greedy algorithm. The method leverages pre-computed QAOA angles, derived from depth-$p$ QAOA circuits on regular trees, to compute local expectation values and inform sequential g...

[View on arXiv](http://arxiv.org/abs/2601.21923v1) | [PDF](https://arxiv.org/pdf/2601.21923v1)

---

### [Hierarchy of discriminative power and complexity in learning quantum ensembles](http://arxiv.org/abs/2601.22005v1)
**Authors:** Jian Yao, Pengtao Li, Xiaohui Chen et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph, math.ST, stat.ML  

**Abstract:** Distance metrics are central to machine learning, yet distances between ensembles of quantum states remain poorly understood due to fundamental quantum measurement constraints. We introduce a hierarchy of integral probability metrics, termed MMD-$k$, which generalizes the maximum mean discrepancy to quantum ensembles and exhibit a strict trade-off between discriminative power and statistical effic...

[View on arXiv](http://arxiv.org/abs/2601.22005v1) | [PDF](https://arxiv.org/pdf/2601.22005v1)

---

### [Designing quantum technologies with a quantum computer](http://arxiv.org/abs/2601.22091v1)
**Authors:** Juan Naranjo, Thi Ha Kyaw, Gaurav Saxena et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph, cond-mat.mtrl-sci  

**Abstract:** Interacting spin systems in solids underpin a wide range of quantum technologies, from quantum sensors and single-photon sources to spin-defect-based quantum registers and processors. We develop a quantum-computer-aided framework for simulating such devices using a general electron spin resonance Hamiltonian incorporating zero-field splitting, the Zeeman effect, hyperfine interactions, dipole-dipo...

[View on arXiv](http://arxiv.org/abs/2601.22091v1) | [PDF](https://arxiv.org/pdf/2601.22091v1)

---

### [Photonic Links for Spin-Based Quantum Sensors](http://arxiv.org/abs/2601.22011v1)
**Authors:** M. Reefaz Rahman, Karsten Schnier, Ryan Goldsmith et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph, physics.app-ph  

**Abstract:** A growing variety of optically accessible spin qubits have emerged in recent years as key components for quantum sensors, qubits, and quantum memories. However, the scalability of conventional spin-based quantum architectures remains limited by direct microwave delivery, which introduces thermal noise, electromagnetic cross-talk, and design constraints for cryogenic, high-field, and distributed sy...

[View on arXiv](http://arxiv.org/abs/2601.22011v1) | [PDF](https://arxiv.org/pdf/2601.22011v1)

---

### [Fabrication effects on Niobium oxidation and surface contamination in Niobium-metal bilayers using X-ray photoelectron spectroscopy](http://arxiv.org/abs/2601.21953v1)
**Authors:** Tathagata Banerjee, Maciej W. Olszewski, Valla Fatemi  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cond-mat.mtrl-sci, quant-ph  

**Abstract:** Superconducting resonators and qubits are limited by dielectric losses from surface oxides. Surface oxides are mitigated through various strategies such as the addition of a metal capping layer, surface passivation, and acid processing. In this study, we demonstrate the use of X-ray photoelectron spectroscopy (XPS) as a rapid characterization tool to study the effectiveness cap layers for niobium ...

[View on arXiv](http://arxiv.org/abs/2601.21953v1) | [PDF](https://arxiv.org/pdf/2601.21953v1)

---

### [Entropy production versus memory effects in two-level open quantum systems](http://arxiv.org/abs/2601.21930v1)
**Authors:** Guillaume Théret, Dominique Sugny, Camille L. Latune  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph  

**Abstract:** We compare several definitions of entropy production rate introduced in the literature from a large variety of situations and motivations, and then analyze their relations with memory effects. Considering a relevant experimental example of a qubit interacting with a single bosonic mode playing the role of a finite bath, we show that all definitions of entropy production coincide at weak coupling. ...

[View on arXiv](http://arxiv.org/abs/2601.21930v1) | [PDF](https://arxiv.org/pdf/2601.21930v1)

---

### [RedSage: A Cybersecurity Generalist LLM](http://arxiv.org/abs/2601.22159v1)
**Authors:** Naufal Suryanto, Muzammal Naseer, Pengfei Li et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CR, cs.AI, cs.CL  

**Abstract:** Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, ...

[View on arXiv](http://arxiv.org/abs/2601.22159v1) | [PDF](https://arxiv.org/pdf/2601.22159v1)

---

### [Discovering Hidden Gems in Model Repositories](http://arxiv.org/abs/2601.22157v1)
**Authors:** Jonathan Kahana, Eliahu Horwitz, Yedid Hoshen  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.CL  

**Abstract:** Public repositories host millions of fine-tuned models, yet community usage remains disproportionately concentrated on a small number of foundation checkpoints. We investigate whether this concentration reflects efficient market selection or if superior models are systematically overlooked. Through an extensive evaluation of over 2,000 models, we show the prevalence of "hidden gems", unpopular fin...

[View on arXiv](http://arxiv.org/abs/2601.22157v1) | [PDF](https://arxiv.org/pdf/2601.22157v1)

---

### [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](http://arxiv.org/abs/2601.22156v1)
**Authors:** Yingfa Chen, Zhen Leng Thai, Zihan Zhou et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN...

[View on arXiv](http://arxiv.org/abs/2601.22156v1) | [PDF](https://arxiv.org/pdf/2601.22156v1)

---

### [Exploring Reasoning Reward Model for Agents](http://arxiv.org/abs/2601.22154v1)
**Authors:** Kaixuan Fan, Kaituo Feng, Manyuan Zhang et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.AI, cs.CL  

**Abstract:** Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a mult...

[View on arXiv](http://arxiv.org/abs/2601.22154v1) | [PDF](https://arxiv.org/pdf/2601.22154v1)

---

### [Late Breaking Results: Conversion of Neural Networks into Logic Flows for Edge Computing](http://arxiv.org/abs/2601.22151v1)
**Authors:** Daniel Stein, Shaoyi Huang, Rolf Drechsler et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, eess.SY  

**Abstract:** Neural networks have been successfully applied in various resource-constrained edge devices, where usually central processing units (CPUs) instead of graphics processing units exist due to limited power availability. State-of-the-art research still focuses on efficiently executing enormous numbers of multiply-accumulate (MAC) operations. However, CPUs themselves are not good at executing such math...

[View on arXiv](http://arxiv.org/abs/2601.22151v1) | [PDF](https://arxiv.org/pdf/2601.22151v1)

---

### [DynaWeb: Model-Based Reinforcement Learning of Web Agents](http://arxiv.org/abs/2601.22149v1)
**Authors:** Hang Ding, Peidong Liu, Junqiao Wang et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.AI  

**Abstract:** The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a pr...

[View on arXiv](http://arxiv.org/abs/2601.22149v1) | [PDF](https://arxiv.org/pdf/2601.22149v1)

---

### [FineInstructions: Scaling Synthetic Instructions to Pre-Training Scale](http://arxiv.org/abs/2601.22146v1)
**Authors:** Ajay Patel, Colin Raffel, Chris Callison-Burch  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.LG  

**Abstract:** Due to limited supervised training data, large language models (LLMs) are typically pre-trained via a self-supervised "predict the next word" objective on a vast amount of unstructured text data. To make the resulting model useful to users, it is further trained on a far smaller amount of "instruction-tuning" data comprised of supervised training examples of instructions and responses. To overcome...

[View on arXiv](http://arxiv.org/abs/2601.22146v1) | [PDF](https://arxiv.org/pdf/2601.22146v1)

---

### [Routing the Lottery: Adaptive Subnetworks for Heterogeneous Data](http://arxiv.org/abs/2601.22141v1)
**Authors:** Grzegorz Stefanski, Alberto Presta, Michal Byra  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.AI, cs.CV, cs.LG  

**Abstract:** In pruning, the Lottery Ticket Hypothesis posits that large networks contain sparse subnetworks, or winning tickets, that can be trained in isolation to match the performance of their dense counterparts. However, most existing approaches assume a single universal winning ticket shared across all inputs, ignoring the inherent heterogeneity of real-world data. In this work, we propose Routing the Lo...

[View on arXiv](http://arxiv.org/abs/2601.22141v1) | [PDF](https://arxiv.org/pdf/2601.22141v1)

---

### [Quantum fluctuations in hydrodynamics and quantum long-time tails](http://arxiv.org/abs/2601.22140v1)
**Authors:** Akash Jain  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** hep-th, cond-mat.stat-mech, hep-ph, math-ph, quant-ph  

**Abstract:** We construct a quantum Schwinger-Keldysh (SK) effective field theory for the diffusive hydrodynamics of a conserved scalar field. Quantum corrections within the SK framework are guided by fluctuation-dissipation relations, enforced via a dynamical Kubo-Martin-Schwinger (KMS) symmetry. We find that the KMS symmetry necessarily generates fluctuation contributions in the SK effective action at all or...

[View on arXiv](http://arxiv.org/abs/2601.22140v1) | [PDF](https://arxiv.org/pdf/2601.22140v1)

---

### [Reasoning While Asking: Transforming Reasoning Large Language Models from Passive Solvers to Proactive Inquirers](http://arxiv.org/abs/2601.22139v1)
**Authors:** Xin Chen, Feng Jiang, Yiqian Zhang et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.AI  

**Abstract:** Reasoning-oriented Large Language Models (LLMs) have achieved remarkable progress with Chain-of-Thought (CoT) prompting, yet they remain fundamentally limited by a \emph{blind self-thinking} paradigm: performing extensive internal reasoning even when critical information is missing or ambiguous. We propose Proactive Interactive Reasoning (PIR), a new reasoning paradigm that transforms LLMs from pa...

[View on arXiv](http://arxiv.org/abs/2601.22139v1) | [PDF](https://arxiv.org/pdf/2601.22139v1)

---

### [StepShield: When, Not Whether to Intervene on Rogue Agents](http://arxiv.org/abs/2601.22136v1)
**Authors:** Gloria Felicia, Michael Eniolade, Jinfeng He et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.AI, cs.CR, cs.SE  

**Abstract:** Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, ...

[View on arXiv](http://arxiv.org/abs/2601.22136v1) | [PDF](https://arxiv.org/pdf/2601.22136v1)

---

### [Pay for Hints, Not Answers: LLM Shepherding for Cost-Efficient Inference](http://arxiv.org/abs/2601.22132v1)
**Authors:** Ziming Dong, Hardik Sharma, Evan O'Toole et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Large Language Models (LLMs) deliver state-of-the-art performance on complex reasoning tasks, but their inference costs limit deployment at scale. Small Language Models (SLMs) offer dramatic cost savings yet lag substantially in accuracy. Existing approaches - routing and cascading - treat the LLM as an all-or-nothing resource: either the query bypasses the LLM entirely, or the LLM generates a com...

[View on arXiv](http://arxiv.org/abs/2601.22132v1) | [PDF](https://arxiv.org/pdf/2601.22132v1)

---

### [SMOG: Scalable Meta-Learning for Multi-Objective Bayesian Optimization](http://arxiv.org/abs/2601.22131v1)
**Authors:** Leonard Papenmeier, Petru Tighineanu  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Multi-objective optimization aims to solve problems with competing objectives, often with only black-box access to a problem and a limited budget of measurements. In many applications, historical data from related optimization tasks is available, creating an opportunity for meta-learning to accelerate the optimization. Bayesian optimization, as a promising technique for black-box optimization, has...

[View on arXiv](http://arxiv.org/abs/2601.22131v1) | [PDF](https://arxiv.org/pdf/2601.22131v1)

---

### [World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems](http://arxiv.org/abs/2601.22130v1)
**Authors:** Lakshya Gupta, Litao Li, Yizhe Liu et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.AI, cs.SE  

**Abstract:** Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observa...

[View on arXiv](http://arxiv.org/abs/2601.22130v1) | [PDF](https://arxiv.org/pdf/2601.22130v1)

---

### [SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents](http://arxiv.org/abs/2601.22129v1)
**Authors:** Yifeng Ding, Lingming Zhang  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.SE, cs.AI, cs.LG  

**Abstract:** Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to genera...

[View on arXiv](http://arxiv.org/abs/2601.22129v1) | [PDF](https://arxiv.org/pdf/2601.22129v1)

---

### [The Patient is not a Moving Document: A World Model Training Paradigm for Longitudinal EHR](http://arxiv.org/abs/2601.22128v1)
**Authors:** Irsyad Adam, Zekai Chen, David Laprade et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.AI, cs.CE, q-bio.QM  

**Abstract:** Large language models (LLMs) trained with next-word-prediction have achieved success as clinical foundation models. Representations from these language backbones yield strong linear probe performance across biomedical tasks, suggesting that patient semantics emerge from next-token prediction at scale. However, this paradigm treats patients as a document to be summarized rather than a dynamical sys...

[View on arXiv](http://arxiv.org/abs/2601.22128v1) | [PDF](https://arxiv.org/pdf/2601.22128v1)

---

### [EditYourself: Audio-Driven Generation and Manipulation of Talking Head Videos with Diffusion Transformers](http://arxiv.org/abs/2601.22127v1)
**Authors:** John Flynn, Wolfgang Paier, Dimitar Dinev et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CV, cs.GR, cs.LG, cs.MM  

**Abstract:** Current generative video models excel at producing novel content from text and image prompts, but leave a critical gap in editing existing pre-recorded videos, where minor alterations to the spoken script require preserving motion, temporal coherence, speaker identity, and accurate lip synchronization. We introduce EditYourself, a DiT-based framework for audio-driven video-to-video (V2V) editing t...

[View on arXiv](http://arxiv.org/abs/2601.22127v1) | [PDF](https://arxiv.org/pdf/2601.22127v1)

---

### [Learning Hamiltonian Flow Maps: Mean Flow Consistency for Large-Timestep Molecular Dynamics](http://arxiv.org/abs/2601.22123v1)
**Authors:** Winfried Ripken, Michael Plainer, Gregor Lied et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Simulating the long-time evolution of Hamiltonian systems is limited by the small timesteps required for stable numerical integration. To overcome this constraint, we introduce a framework to learn Hamiltonian Flow Maps by predicting the mean phase-space evolution over a chosen time span $Δt$, enabling stable large-timestep updates far beyond the stability limits of classical integrators. To this ...

[View on arXiv](http://arxiv.org/abs/2601.22123v1) | [PDF](https://arxiv.org/pdf/2601.22123v1)

---

### [Alpha Discovery via Grammar-Guided Learning and Search](http://arxiv.org/abs/2601.22119v1)
**Authors:** Han Yang, Dong Hao, Zhuohan Wang et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** q-fin.CP, cs.AI, cs.LG  

**Abstract:** Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally ef...

[View on arXiv](http://arxiv.org/abs/2601.22119v1) | [PDF](https://arxiv.org/pdf/2601.22119v1)

---

### [Defining Operational Conditions for Safety-Critical AI-Based Systems from Data](http://arxiv.org/abs/2601.22118v1)
**Authors:** Johann Christensen, Elena Hoemann, Frank Köster et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.AI  

**Abstract:** Artificial Intelligence (AI) has been on the rise in many domains, including numerous safety-critical applications. However, for complex systems found in the real world, or when data already exist, defining the underlying environmental conditions is extremely challenging. This often results in an incomplete description of the environment in which the AI-based system must operate. Nevertheless, thi...

[View on arXiv](http://arxiv.org/abs/2601.22118v1) | [PDF](https://arxiv.org/pdf/2601.22118v1)

---

### [SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence](http://arxiv.org/abs/2601.22114v1)
**Authors:** Saoud Aldowaish, Yashwanth Karumanchi, Kai-Chen Chiang et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CV, cs.AI, eess.SY  

**Abstract:** Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and...

[View on arXiv](http://arxiv.org/abs/2601.22114v1) | [PDF](https://arxiv.org/pdf/2601.22114v1)

---

### [Diverse Approaches to Optimal Execution Schedule Generation](http://arxiv.org/abs/2601.22113v1)
**Authors:** Robert de Witt, Mikko S. Pakkanen  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** q-fin.TR, cs.LG  

**Abstract:** We present the first application of MAP-Elites, a quality-diversity algorithm, to trade execution. Rather than searching for a single optimal policy, MAP-Elites generates a diverse portfolio of regime-specialist strategies indexed by liquidity and volatility conditions. Individual specialists achieve 8-10% performance improvements within their behavioural niches, while other cells show degradation...

[View on arXiv](http://arxiv.org/abs/2601.22113v1) | [PDF](https://arxiv.org/pdf/2601.22113v1)

---

### [Physics Informed Reconstruction of Four-Dimensional Atmospheric Wind Fields Using Multi-UAS Swarm Observations in a Synthetic Turbulent Environment](http://arxiv.org/abs/2601.22111v1)
**Authors:** Abdullah Tasim, Wei Sun  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, eess.SY, physics.ao-ph  

**Abstract:** Accurate reconstruction of atmospheric wind fields is essential for applications such as weather forecasting, hazard prediction, and wind energy assessment, yet conventional instruments leave spatio-temporal gaps within the lower atmospheric boundary layer. Unmanned aircraft systems (UAS) provide flexible in situ measurements, but individual platforms sample wind only along their flight trajectori...

[View on arXiv](http://arxiv.org/abs/2601.22111v1) | [PDF](https://arxiv.org/pdf/2601.22111v1)

---

### [Value-Based Pre-Training with Downstream Feedback](http://arxiv.org/abs/2601.22108v1)
**Authors:** Shuqi Ke, Giulia Fanti  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.AI  

**Abstract:** Can a small amount of verified goal information steer the expensive self-supervised pretraining of foundation models? Standard pretraining optimizes a fixed proxy objective (e.g., next-token prediction), which can misallocate compute away from downstream capabilities of interest. We introduce V-Pretraining: a value-based, modality-agnostic method for controlled continued pretraining in which a lig...

[View on arXiv](http://arxiv.org/abs/2601.22108v1) | [PDF](https://arxiv.org/pdf/2601.22108v1)

---

### [Prior-Informed Flow Matching for Graph Reconstruction](http://arxiv.org/abs/2601.22107v1)
**Authors:** Harvey Chen, Nicolas Zilberstein, Santiago Segarra  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** We introduce Prior-Informed Flow Matching (PIFM), a conditional flow model for graph reconstruction. Reconstructing graphs from partial observations remains a key challenge; classical embedding methods often lack global consistency, while modern generative models struggle to incorporate structural priors. PIFM bridges this gap by integrating embedding-based priors with continuous-time flow matchin...

[View on arXiv](http://arxiv.org/abs/2601.22107v1) | [PDF](https://arxiv.org/pdf/2601.22107v1)

---

### [ECO: Quantized Training without Full-Precision Master Weights](http://arxiv.org/abs/2601.22101v1)
**Authors:** Mahdi Nikdan, Amir Zandieh, Dan Alistarh et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit{master weights}$. This buffer introduces substantial memory overhead, particularly for Sparse Mixtu...

[View on arXiv](http://arxiv.org/abs/2601.22101v1) | [PDF](https://arxiv.org/pdf/2601.22101v1)

---

### [Boosting CVaR Policy Optimization with Quantile Gradients](http://arxiv.org/abs/2601.22100v1)
**Authors:** Yudong Luo, Erick Delage  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Optimizing Conditional Value-at-risk (CVaR) using policy gradient (a.k.a CVaR-PG) faces significant challenges of sample inefficiency. This inefficiency stems from the fact that it focuses on tail-end performance and overlooks many sampled trajectories. We address this problem by augmenting CVaR with an expected quantile term. Quantile optimization admits a dynamic programming formulation that lev...

[View on arXiv](http://arxiv.org/abs/2601.22100v1) | [PDF](https://arxiv.org/pdf/2601.22100v1)

---

### [GeoNorm: Unify Pre-Norm and Post-Norm with Geodesic Optimization](http://arxiv.org/abs/2601.22095v1)
**Authors:** Chuanyang Zheng, Jiankai Sun, Yihang Gao et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.CL  

**Abstract:** The placement of normalization layers, specifically Pre-Norm and Post-Norm, remains an open question in Transformer architecture design. In this work, we rethink these approaches through the lens of manifold optimization, interpreting the outputs of the Feed-Forward Network (FFN) and attention layers as update directions in optimization. Building on this perspective, we introduce GeoNorm, a novel ...

[View on arXiv](http://arxiv.org/abs/2601.22095v1) | [PDF](https://arxiv.org/pdf/2601.22095v1)

---

### [Where Do the Joules Go? Diagnosing Inference Energy Consumption](http://arxiv.org/abs/2601.22076v1)
**Authors:** Jae-Won Chung, Ruofan Wu, Jeff J. Ma et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.DC  

**Abstract:** Energy is now a critical ML computing resource. While measuring energy consumption and observing trends is a valuable first step, accurately understanding and diagnosing why those differences occur is crucial for optimization. To that end, we begin by presenting a large-scale measurement study of inference time and energy across the generative AI landscape with 46 models, 7 tasks, and 1,858 differ...

[View on arXiv](http://arxiv.org/abs/2601.22076v1) | [PDF](https://arxiv.org/pdf/2601.22076v1)

---

### [Thermodynamics of linear open quantum walks](http://arxiv.org/abs/2601.22064v1)
**Authors:** Pedro Linck Maciel, Nadja Kolb Bernardes  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** quant-ph  

**Abstract:** Open quantum systems interact with their environment, leading to nonunitary dynamics. We investigate the thermodynamics of linear Open Quantum Walks (OQWs), a class of quantum walks whose dynamics is entirely driven by the environment. We define an equilibrium temperature, identify a population inversion near a finite critical value of a control parameter, analyze the thermalization process, and d...

[View on arXiv](http://arxiv.org/abs/2601.22064v1) | [PDF](https://arxiv.org/pdf/2601.22064v1)

---

### [Cross-Fusion Distance: A Novel Metric for Measuring Fusion and Separability Between Data Groups in Representation Space](http://arxiv.org/abs/2601.22036v1)
**Authors:** Xiaolong Zhang, Jianwei Zhang, Xubo Song  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Quantifying degrees of fusion and separability between data groups in representation space is a fundamental problem in representation learning, particularly under domain shift. A meaningful metric should capture fusion-altering factors like geometric displacement between representation groups, whose variations change the extent of fusion, while remaining invariant to fusion-preserving factors such...

[View on arXiv](http://arxiv.org/abs/2601.22036v1) | [PDF](https://arxiv.org/pdf/2601.22036v1)

---

### [Holographic generative flows with AdS/CFT](http://arxiv.org/abs/2601.22033v1)
**Authors:** Ehsan Mirafzali, Sanjit Shashi, Sanya Murdeshwar et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, gr-qc, hep-th  

**Abstract:** We present a framework for generative machine learning that leverages the holographic principle of quantum gravity, or to be more precise its manifestation as the anti-de Sitter/conformal field theory (AdS/CFT) correspondence, with techniques for deep learning and transport theory. Our proposal is to represent the flow of data from a base distribution to some learned distribution using the bulk-to...

[View on arXiv](http://arxiv.org/abs/2601.22033v1) | [PDF](https://arxiv.org/pdf/2601.22033v1)

---

### [Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units](http://arxiv.org/abs/2601.21996v1)
**Authors:** Jianhui Chen, Yuzhang Luo, Liangming Pan  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted interventi...

[View on arXiv](http://arxiv.org/abs/2601.21996v1) | [PDF](https://arxiv.org/pdf/2601.21996v1)

---

### [Elign: Equivariant Diffusion Model Alignment from Foundational Machine Learning Force Fields](http://arxiv.org/abs/2601.21985v1)
**Authors:** Yunyang Li, Lin Huang, Luojia Xia et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Generative models for 3D molecular conformations must respect Euclidean symmetries and concentrate probability mass on thermodynamically favorable, mechanically stable structures. However, E(3)-equivariant diffusion models often reproduce biases from semi-empirical training data rather than capturing the equilibrium distribution of a high-fidelity Hamiltonian. While physics-based guidance can corr...

[View on arXiv](http://arxiv.org/abs/2601.21985v1) | [PDF](https://arxiv.org/pdf/2601.21985v1)

---

### [PowerGenie: Analytically-Guided Evolutionary Discovery of Superior Reconfigurable Power Converters](http://arxiv.org/abs/2601.21984v1)
**Authors:** Jian Gao, Yiwei Zou, Abhishek Pradhan et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG, cs.AR  

**Abstract:** Discovering superior circuit topologies requires navigating an exponentially large design space-a challenge traditionally reserved for human experts. Existing AI methods either select from predefined templates or generate novel topologies at a limited scale without rigorous verification, leaving large-scale performance-driven discovery underexplored. We present PowerGenie, a framework for automate...

[View on arXiv](http://arxiv.org/abs/2601.21984v1) | [PDF](https://arxiv.org/pdf/2601.21984v1)

---

### [Investigating Batch Inference in a Sequential Monte Carlo Framework for Neural Networks](http://arxiv.org/abs/2601.21983v1)
**Authors:** Andrew Millard, Joshua Murphy, Peter Green et al.  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cs.LG  

**Abstract:** Bayesian inference allows us to define a posterior distribution over the weights of a generic neural network (NN). Exact posteriors are usually intractable, in which case approximations can be employed. One such approximation - variational inference - is computationally efficient when using mini-batch stochastic gradient descent as subsets of the data are used for likelihood and gradient evaluatio...

[View on arXiv](http://arxiv.org/abs/2601.21983v1) | [PDF](https://arxiv.org/pdf/2601.21983v1)

---

### [Bound-state-free Förster resonant shielding of strongly dipolar ultracold molecules](http://arxiv.org/abs/2601.21928v1)
**Authors:** Reuben R. W. Wang  
**Published:** 2026-01-29  
**Updated:** 2026-01-29  
**Categories:** cond-mat.quant-gas, physics.atom-ph, quant-ph  

**Abstract:** We propose a method to suppress collisional loss in strongly dipolar, rotationally excited ultracold molecules using a combination of static (dc) and microwave (ac) electric fields. By tuning two excited pair molecular rotational states into a Förster resonance with a dc field, simultaneously driving excited rotational transitions with an ac field removes all long-range bound states, allowing near...

[View on arXiv](http://arxiv.org/abs/2601.21928v1) | [PDF](https://arxiv.org/pdf/2601.21928v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
