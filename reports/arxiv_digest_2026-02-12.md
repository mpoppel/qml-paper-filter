# arXiv Daily Digest - 2026-02-12

**Search Period:** Last 7 days  
**Papers Found:** 39

## Summary

This digest includes papers on:
- Quantum circuits for machine learning
- Fourier analysis of quantum models
- Variational quantum algorithms
- Barren plateaus and trainability
- Data encoding strategies

---

## Papers


### [Characterizing Trainability of Instantaneous Quantum Polynomial Circuit Born Machines](http://arxiv.org/abs/2602.11042v1)
**Authors:** Kevin Shen, Susanne Pielawa, Vedran Dunjko et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph, cs.LG  

**Abstract:** Instantaneous quantum polynomial quantum circuit Born machines (IQP-QCBMs) have been proposed as quantum generative models with a classically tractable training objective based on the maximum mean discrepancy (MMD) and a potential quantum advantage motivated by sampling-complexity arguments, making them an exciting model worth deeper investigation. While recent works have further proven the univer...

[View on arXiv](http://arxiv.org/abs/2602.11042v1) | [PDF](https://arxiv.org/pdf/2602.11042v1)

---

### [Direct Learning of Calibration-Aware Uncertainty for Neural PDE Surrogates](http://arxiv.org/abs/2602.11090v1)
**Authors:** Carlos Stein Brito  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.AI, cs.CE, stat.CO  

**Abstract:** Neural PDE surrogates are often deployed in data-limited or partially observed regimes where downstream decisions depend on calibrated uncertainty in addition to low prediction error. Existing approaches obtain uncertainty through ensemble replication, fixed stochastic noise such as dropout, or post hoc calibration. Cross-regularized uncertainty learns uncertainty parameters during training using ...

[View on arXiv](http://arxiv.org/abs/2602.11090v1) | [PDF](https://arxiv.org/pdf/2602.11090v1)

---

### [Two-Level System Spectroscopy from Correlated Multilevel Relaxation in Superconducting Qubits](http://arxiv.org/abs/2602.11127v1)
**Authors:** Tanay Roy, Xinyuan You, David van Zanten et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph  

**Abstract:** Transmon qubits are a cornerstone of modern superconducting quantum computing platforms. Temporal fluctuations of energy relaxation in these qubits are widely attributed to microscopic two-level systems (TLSs) in device dielectrics and interfaces, yet isolating individual defects typically relies on tuning the qubit or the TLS into resonance. We demonstrate a novel spectroscopy method for fixed-fr...

[View on arXiv](http://arxiv.org/abs/2602.11127v1) | [PDF](https://arxiv.org/pdf/2602.11127v1)

---

### [MerLin: A Discovery Engine for Photonic and Hybrid Quantum Machine Learning](http://arxiv.org/abs/2602.11092v1)
**Authors:** Cassandre Notton, Benjamin Stott, Philippe Schoeb et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.PL, quant-ph  

**Abstract:** Identifying where quantum models may offer practical benefits in near term quantum machine learning (QML) requires moving beyond isolated algorithmic proposals toward systematic and empirical exploration across models, datasets, and hardware constraints. We introduce MerLin, an open source framework designed as a discovery engine for photonic and hybrid quantum machine learning. MerLin integrates ...

[View on arXiv](http://arxiv.org/abs/2602.11092v1) | [PDF](https://arxiv.org/pdf/2602.11092v1)

---

### [SCRAPL: Scattering Transform with Random Paths for Machine Learning](http://arxiv.org/abs/2602.11145v1)
**Authors:** Christopher Mitcheltree, Vincent Lostanlen, Emmanouil Benetos et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.SD, cs.LG, eess.AS  

**Abstract:** The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which ...

[View on arXiv](http://arxiv.org/abs/2602.11145v1) | [PDF](https://arxiv.org/pdf/2602.11145v1)

---

### [Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows](http://arxiv.org/abs/2602.11142v1)
**Authors:** Shaswat Garg, Matin Moezzi, Brandon Da Silva  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.RO, cs.AI, cs.LG  

**Abstract:** Hierarchical goal-conditioned reinforcement learning (H-GCRL) provides a powerful framework for tackling complex, long-horizon tasks by decomposing them into structured subgoals. However, its practical adoption is hindered by poor data efficiency and limited policy expressivity, especially in offline or data-scarce regimes. In this work, Normalizing flow-based hierarchical implicit Q-learning (NF-...

[View on arXiv](http://arxiv.org/abs/2602.11142v1) | [PDF](https://arxiv.org/pdf/2602.11142v1)

---

### [From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers](http://arxiv.org/abs/2602.11130v1)
**Authors:** Maximilian Plattner, Fabian Paischer, Johannes Brandstetter et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.CV  

**Abstract:** Reliable surface completion from sparse point clouds underpins many applications spanning content creation and robotics. While 3D diffusion transformers attain state-of-the-art results on this task, we uncover that they exhibit a catastrophic mode of failure: arbitrarily small on-surface perturbations to the input point cloud can fracture the output into multiple disconnected pieces -- a phenomeno...

[View on arXiv](http://arxiv.org/abs/2602.11130v1) | [PDF](https://arxiv.org/pdf/2602.11130v1)

---

### [Floquet Control of Electron and Exciton Transport in Kekulé-Distorted Graphene](http://arxiv.org/abs/2602.11119v1)
**Authors:** Sita Kandel, Godfrey Gumbs  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cond-mat.mes-hall, quant-ph  

**Abstract:** This work investigates the Floquet dynamics of electrons and excitons (particle-hole pairs) in a Dirac material referred to as Kekulé-distorted graphene. Specifically, we examine the role played by a high frequency driving electromagnetic field on the tunneling and blocking by a potential barrier on both the charged single particles as well as the neutral composite particles. We demonstrate that t...

[View on arXiv](http://arxiv.org/abs/2602.11119v1) | [PDF](https://arxiv.org/pdf/2602.11119v1)

---

### [Improving Quantum Multi-Objective Optimization with Archiving and Substitution](http://arxiv.org/abs/2602.10952v1)
**Authors:** Linus Ekstrøm, Takafumi Hosogi, Xavier Bonet-Monroig et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph  

**Abstract:** Finding optimal solutions of conflicting objectives is a daily matter in many industrial applications, with multi-objective optimization trying to find the best solutions to them. The advent of quantum computing has led to researchers wondering if the promised exponential advantage can be obtained for these problems by variational quantum multi-objective optimization (QMOO) algorithm. Here, we imp...

[View on arXiv](http://arxiv.org/abs/2602.10952v1) | [PDF](https://arxiv.org/pdf/2602.10952v1)

---

### [Quantum Optimization in Loc(Q)ation Science: QUBO Formulations, Benchmark Problems, and a Computational Study](http://arxiv.org/abs/2602.10951v1)
**Authors:** Felix P. Broesamle, Stefan Nickel  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph  

**Abstract:** Recent advances in quantum computing and the increasing availability of quantum hardware have substantially enhanced the practical relevance of quantum approaches to discrete optimization. Among these, the Quadratic Unconstrained Binary Optimization (QUBO) formulation provides a unifying modeling framework for a broad class of $\mathbf{NP}$-hard problems and is naturally suited to quantum computin...

[View on arXiv](http://arxiv.org/abs/2602.10951v1) | [PDF](https://arxiv.org/pdf/2602.10951v1)

---

### [Ergotropic Mpemba crossings in finite-dimensional quantum batteries](http://arxiv.org/abs/2602.11056v1)
**Authors:** Triyas Sapui, Tanoy Kanti Konar, Aditi Sen De  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph, cond-mat.stat-mech  

**Abstract:** The quantum Mpemba effect is a counterintuitive phenomenon in which a state initially farther from equilibrium relaxes more rapidly than one that starts nearer to equilibrium. In the context of finite-dimensional quantum batteries interacting with an environment, we introduce the notion of an ergotropic Mpemba crossing (EMC), defined by the intersection of ergotropy trajectories during the dynamic...

[View on arXiv](http://arxiv.org/abs/2602.11056v1) | [PDF](https://arxiv.org/pdf/2602.11056v1)

---

### [Recirculating Quantum Photonic Networks for Fast Deterministic Quantum Information Processing](http://arxiv.org/abs/2602.11033v1)
**Authors:** Emil Grovn, Matias Bundgaard-Nielsen, Jesper Mørk et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** quant-ph  

**Abstract:** A fundamental challenge in photonics-based deterministic quantum information processing is to realize key transformations on time scales shorter than those of detrimental decoherence and loss mechanisms. This challenge has been addressed through device-focused approaches that aim to increase nonlinear interactions relative to decoherence rates. In this work, we adopt a complementary architecture-f...

[View on arXiv](http://arxiv.org/abs/2602.11033v1) | [PDF](https://arxiv.org/pdf/2602.11033v1)

---

### [Diffusion-Pretrained Dense and Contextual Embeddings](http://arxiv.org/abs/2602.11151v1)
**Authors:** Sedigheh Eslami, Maksim Gaiduk, Markus Krimmel et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.CL, cs.IR  

**Abstract:** In this report, we introduce pplx-embed, a family of multilingual embedding models that employ multi-stage contrastive learning on a diffusion-pretrained language model backbone for web-scale retrieval. By leveraging bidirectional attention through diffusion-based pretraining, our models capture comprehensive bidirectional context within passages, enabling the use of mean pooling and a late chunki...

[View on arXiv](http://arxiv.org/abs/2602.11151v1) | [PDF](https://arxiv.org/pdf/2602.11151v1)

---

### [YOR: Your Own Mobile Manipulator for Generalizable Robotics](http://arxiv.org/abs/2602.11150v1)
**Authors:** Manan H Anjaria, Mehmet Enes Erciyes, Vedant Ghatnekar et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.RO, cs.LG  

**Abstract:** Recent advances in robot learning have generated significant interest in capable platforms that may eventually approach human-level competence. This interest, combined with the commoditization of actuators, has propelled growth in low-cost robotic platforms. However, the optimal form factor for mobile manipulation, especially on a budget, remains an open question. We introduce YOR, an open-source,...

[View on arXiv](http://arxiv.org/abs/2602.11150v1) | [PDF](https://arxiv.org/pdf/2602.11150v1)

---

### [Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling](http://arxiv.org/abs/2602.11146v1)
**Authors:** Gongye Liu, Bo Yang, Yida Zhi et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.CV, cs.AI  

**Abstract:** Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator...

[View on arXiv](http://arxiv.org/abs/2602.11146v1) | [PDF](https://arxiv.org/pdf/2602.11146v1)

---

### [GENIUS: Generative Fluid Intelligence Evaluation Suite](http://arxiv.org/abs/2602.11144v1)
**Authors:** Ruichuan An, Sihan Yang, Ziyu Guo et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.AI, cs.CV  

**Abstract:** Unified Multimodal Models (UMMs) have shown remarkable progress in visual generation. Yet, existing benchmarks predominantly assess $\textit{Crystallized Intelligence}$, which relies on recalling accumulated knowledge and learned schemas. This focus overlooks $\textit{Generative Fluid Intelligence (GFI)}$: the capacity to induce patterns, reason through constraints, and adapt to novel scenarios on...

[View on arXiv](http://arxiv.org/abs/2602.11144v1) | [PDF](https://arxiv.org/pdf/2602.11144v1)

---

### [LCIP: Loss-Controlled Inverse Projection of High-Dimensional Image Data](http://arxiv.org/abs/2602.11141v1)
**Authors:** Yu Wang, Frederik L. Dennig, Michael Behrisch et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.HC, cs.LG  

**Abstract:** Projections (or dimensionality reduction) methods $P$ aim to map high-dimensional data to typically 2D scatterplots for visual exploration. Inverse projection methods $P^{-1}$ aim to map this 2D space to the data space to support tasks such as data augmentation, classifier analysis, and data imputation. Current $P^{-1}$ methods suffer from a fundamental limitation -- they can only generate a fixed...

[View on arXiv](http://arxiv.org/abs/2602.11141v1) | [PDF](https://arxiv.org/pdf/2602.11141v1)

---

### [TabICLv2: A better, faster, scalable, and open tabular foundation model](http://arxiv.org/abs/2602.11139v1)
**Authors:** Jingang Qu, David Holzmüller, Gaël Varoquaux et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG  

**Abstract:** Tabular foundation models, such as TabPFNv2 and TabICL, have recently dethroned gradient-boosted trees at the top of predictive benchmarks, demonstrating the value of in-context learning for tabular data. We introduce TabICLv2, a new state-of-the-art foundation model for regression and classification built on three pillars: (1) a novel synthetic data generation engine designed for high pretraining...

[View on arXiv](http://arxiv.org/abs/2602.11139v1) | [PDF](https://arxiv.org/pdf/2602.11139v1)

---

### [Weight Decay Improves Language Model Plasticity](http://arxiv.org/abs/2602.11137v1)
**Authors:** Tessa Han, Sebastian Bordt, Hanlin Zhang et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.AI, cs.CL  

**Abstract:** The prevailing paradigm in large language model (LLM) development is to pretrain a base model, then perform further training to improve performance and model behavior. However, hyperparameter optimization and scaling laws have been studied primarily from the perspective of the base model's validation loss, ignoring downstream adaptability. In this work, we study pretraining from the perspective of...

[View on arXiv](http://arxiv.org/abs/2602.11137v1) | [PDF](https://arxiv.org/pdf/2602.11137v1)

---

### [FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight](http://arxiv.org/abs/2602.11136v1)
**Authors:** Jiayi Zhou, Yang Sheng, Hantao Lou et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.AI  

**Abstract:** As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escap...

[View on arXiv](http://arxiv.org/abs/2602.11136v1) | [PDF](https://arxiv.org/pdf/2602.11136v1)

---

### [Just on Time: Token-Level Early Stopping for Diffusion Language Models](http://arxiv.org/abs/2602.11133v1)
**Authors:** Zahar Kohut, Severyn Shykula, Dmytro Khamula et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.CL  

**Abstract:** Diffusion language models generate text through iterative refinement, a process that is often computationally inefficient because many tokens reach stability long before the final denoising step. We introduce a training-free, token-level early stopping approach that identifies convergence independently at each position. Our method leverages lightweight signals derived from the model's predictions ...

[View on arXiv](http://arxiv.org/abs/2602.11133v1) | [PDF](https://arxiv.org/pdf/2602.11133v1)

---

### [Asymmetric Prompt Weighting for Reinforcement Learning with Verifiable Rewards](http://arxiv.org/abs/2602.11128v1)
**Authors:** Reinhard Heckel, Mahdi Soltanolkotabi, Christos Thramboulidis  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG  

**Abstract:** Reinforcement learning with verifiable rewards has driven recent advances in LLM post-training, in particular for reasoning. Policy optimization algorithms generate a number of responses for a given prompt and then effectively weight the corresponding gradients depending on the rewards. The most popular algorithms including GRPO, DAPO, and RLOO focus on ambiguous prompts, i.e., prompts with interm...

[View on arXiv](http://arxiv.org/abs/2602.11128v1) | [PDF](https://arxiv.org/pdf/2602.11128v1)

---

### [The Offline-Frontier Shift: Diagnosing Distributional Limits in Generative Multi-Objective Optimization](http://arxiv.org/abs/2602.11126v1)
**Authors:** Stephanie Holly, Alexandru-Ciprian Zăvoianu, Siegfried Silber et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG  

**Abstract:** Offline multi-objective optimization (MOO) aims to recover Pareto-optimal designs given a finite, static dataset. Recent generative approaches, including diffusion models, show strong performance under hypervolume, yet their behavior under other established MOO metrics is less understood. We show that generative methods systematically underperform evolutionary alternatives with respect to other me...

[View on arXiv](http://arxiv.org/abs/2602.11126v1) | [PDF](https://arxiv.org/pdf/2602.11126v1)

---

### [From Natural Language to Materials Discovery:The Materials Knowledge Navigation Agent](http://arxiv.org/abs/2602.11123v1)
**Authors:** Genmao Zhuang, Amir Barati Farimani  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cond-mat.mtrl-sci  

**Abstract:** Accelerating the discovery of high-performance materials remains a central challenge across energy, electronics, and aerospace technologies, where traditional workflows depend heavily on expert intuition and computationally expensive simulations. Here we introduce the Materials Knowledge Navigation Agent (MKNA), a language-driven system that translates natural-language scientific intent into execu...

[View on arXiv](http://arxiv.org/abs/2602.11123v1) | [PDF](https://arxiv.org/pdf/2602.11123v1)

---

### [Learning to Compose for Cross-domain Agentic Workflow Generation](http://arxiv.org/abs/2602.11114v1)
**Authors:** Jialiang Wang, Shengxiang Xu, Hanmo Liu et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.MA, cs.AI, cs.LG, cs.SE  

**Abstract:** Automatically generating agentic workflows -- executable operator graphs or codes that orchestrate reasoning, verification, and repair -- has become a practical way to solve complex tasks beyond what single-pass LLM generation can reliably handle. Yet what constitutes a good workflow depends heavily on the task distribution and the available operators. Under domain shift, current systems typically...

[View on arXiv](http://arxiv.org/abs/2602.11114v1) | [PDF](https://arxiv.org/pdf/2602.11114v1)

---

### [Nonreciprocal many-body physics](http://arxiv.org/abs/2602.11111v1)
**Authors:** Michel Fruchart, Vincenzo Vitelli  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cond-mat.stat-mech, cond-mat.soft, nlin.PS, quant-ph  

**Abstract:** Reciprocity is a fundamental symmetry present in many natural phenomena and engineered systems. Distinct situations where this symmetry is broken are typically grouped under the umbrella term "nonreciprocity", colloquially defined by: the action of A on B $\neq$ the action of B on A. In this review, we elucidate what nonreciprocity is by providing an introduction to its most salient classes: nonva...

[View on arXiv](http://arxiv.org/abs/2602.11111v1) | [PDF](https://arxiv.org/pdf/2602.11111v1)

---

### [Renet: Principled and Efficient Relaxation for the Elastic Net via Dynamic Objective Selection](http://arxiv.org/abs/2602.11107v1)
**Authors:** Albert Dorador  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** stat.ME, cs.LG, stat.ML  

**Abstract:** We introduce Renet, a principled generalization of the Relaxed Lasso to the Elastic Net family of estimators. While, on the one hand, $\ell_1$-regularization is a standard tool for variable selection in high-dimensional regimes and, on the other hand, the $\ell_2$ penalty provides stability and solution uniqueness through strict convexity, the standard Elastic Net nevertheless suffers from shrinka...

[View on arXiv](http://arxiv.org/abs/2602.11107v1) | [PDF](https://arxiv.org/pdf/2602.11107v1)

---

### [Statistical Learning Analysis of Physics-Informed Neural Networks](http://arxiv.org/abs/2602.11097v1)
**Authors:** David A. Barajas-Solano  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, physics.comp-ph  

**Abstract:** We study the training and performance of physics-informed learning for initial and boundary value problems (IBVP) with physics-informed neural networks (PINNs) from a statistical learning perspective. Specifically, we restrict ourselves to parameterizations with hard initial and boundary condition constraints and reformulate the problem of estimating PINN parameters as a statistical learning probl...

[View on arXiv](http://arxiv.org/abs/2602.11097v1) | [PDF](https://arxiv.org/pdf/2602.11097v1)

---

### [General Flexible $f$-divergence for Challenging Offline RL Datasets with Low Stochasticity and Diverse Behavior Policies](http://arxiv.org/abs/2602.11087v1)
**Authors:** Jianxun Wang, Grant C. Forbes, Leonardo Villalobos-Arias et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.AI  

**Abstract:** Offline RL algorithms aim to improve upon the behavior policy that produces the collected data while constraining the learned policy to be within the support of the dataset. However, practical offline datasets often contain examples with little diversity or limited exploration of the environment, and from multiple behavior policies with diverse expertise levels. Limited exploration can impair the ...

[View on arXiv](http://arxiv.org/abs/2602.11087v1) | [PDF](https://arxiv.org/pdf/2602.11087v1)

---

### [First International StepUP Competition for Biometric Footstep Recognition: Methods, Results and Remaining Challenges](http://arxiv.org/abs/2602.11086v1)
**Authors:** Robyn Larracy, Eve MacDonald, Angkoon Phinyomark et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.CV, cs.LG  

**Abstract:** Biometric footstep recognition, based on a person's unique pressure patterns under their feet during walking, is an emerging field with growing applications in security and safety. However, progress in this area has been limited by the lack of large, diverse datasets necessary to address critical challenges such as generalization to new users and robustness to shifts in factors like footwear or wa...

[View on arXiv](http://arxiv.org/abs/2602.11086v1) | [PDF](https://arxiv.org/pdf/2602.11086v1)

---

### [SteuerLLM: Local specialized large language model for German tax law analysis](http://arxiv.org/abs/2602.11081v1)
**Authors:** Sebastian Wind, Jeta Sopa, Laurin Schmid et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.CL, cs.AI, cs.LG  

**Abstract:** Large language models (LLMs) demonstrate strong general reasoning and language understanding, yet their performance degrades in domains governed by strict formal rules, precise terminology, and legally binding structure. Tax law exemplifies these challenges, as correct answers require exact statutory citation, structured legal argumentation, and numerical accuracy under rigid grading schemes. We a...

[View on arXiv](http://arxiv.org/abs/2602.11081v1) | [PDF](https://arxiv.org/pdf/2602.11081v1)

---

### [In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution](http://arxiv.org/abs/2602.11079v1)
**Authors:** Frank Xiao, Santiago Aranguri  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.AI  

**Abstract:** We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapoints that cause specific behaviors and validate these attributions causally by retraining with modified data...

[View on arXiv](http://arxiv.org/abs/2602.11079v1) | [PDF](https://arxiv.org/pdf/2602.11079v1)

---

### [Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing](http://arxiv.org/abs/2602.11076v1)
**Authors:** Kavan Fatehi, Mostafa Rahmani Ghourtani, Amir Sonee et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** eess.SY, cs.AI, eess.SP  

**Abstract:** Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized atte...

[View on arXiv](http://arxiv.org/abs/2602.11076v1) | [PDF](https://arxiv.org/pdf/2602.11076v1)

---

### [MoToRec: Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation](http://arxiv.org/abs/2602.11062v1)
**Authors:** Jialin Liu, Zhaorui Zhang, Ray C. C. Cheung  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG, cs.IR  

**Abstract:** Graph neural networks (GNNs) have revolutionized recommender systems by effectively modeling complex user-item interactions, yet data sparsity and the item cold-start problem significantly impair performance, particularly for new items with limited or no interaction history. While multimodal content offers a promising solution, existing methods result in suboptimal representations for new items du...

[View on arXiv](http://arxiv.org/abs/2602.11062v1) | [PDF](https://arxiv.org/pdf/2602.11062v1)

---

### [Divide, Harmonize, Then Conquer It: Shooting Multi-Commodity Flow Problems with Multimodal Language Models](http://arxiv.org/abs/2602.11057v1)
**Authors:** Xinyu Yuan, Yan Qiao, Zonghui Wang et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.LG  

**Abstract:** The multi-commodity flow (MCF) problem is a fundamental topic in network flow and combinatorial optimization, with broad applications in transportation, communication, and logistics, etc. Nowadays, the rapid expansion of allocation systems has posed challenges for existing optimization engines in balancing optimality and tractability. In this paper, we present Pram, the first ML-based method that ...

[View on arXiv](http://arxiv.org/abs/2602.11057v1) | [PDF](https://arxiv.org/pdf/2602.11057v1)

---

### [Linguistic Indicators of Early Cognitive Decline in the DementiaBank Pitt Corpus: A Statistical and Machine Learning Study](http://arxiv.org/abs/2602.11028v1)
**Authors:** Artsvik Avetisyan, Sachin Kumar  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.CL, cs.AI  

**Abstract:** Background: Subtle changes in spontaneous language production are among the earliest indicators of cognitive decline. Identifying linguistically interpretable markers of dementia can support transparent and clinically grounded screening approaches.   Methods: This study analyzes spontaneous speech transcripts from the DementiaBank Pitt Corpus using three linguistic representations: raw cleaned tex...

[View on arXiv](http://arxiv.org/abs/2602.11028v1) | [PDF](https://arxiv.org/pdf/2602.11028v1)

---

### [Enhancing Predictability of Multi-Tenant DNN Inference for Autonomous Vehicles' Perception](http://arxiv.org/abs/2602.11004v1)
**Authors:** Liangkai Liu, Kang G. Shin, Jinkyu Lee et al.  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cs.CV, cs.AI, cs.RO, eess.SY  

**Abstract:** Autonomous vehicles (AVs) rely on sensors and deep neural networks (DNNs) to perceive their surrounding environment and make maneuver decisions in real time. However, achieving real-time DNN inference in the AV's perception pipeline is challenging due to the large gap between the computation requirement and the AV's limited resources. Most, if not all, of existing studies focus on optimizing the D...

[View on arXiv](http://arxiv.org/abs/2602.11004v1) | [PDF](https://arxiv.org/pdf/2602.11004v1)

---

### [A generalization of Frenkel's formula](http://arxiv.org/abs/2602.10962v1)
**Authors:** Shmuel Friedland  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** math.FA, math-ph, quant-ph  

**Abstract:** We generalize Frenkel's integral formula for traces of operators to operators. The resulting formula holds for bounded self-adjoint positive operators and $p$-Schatten class of compact positive operators.

[View on arXiv](http://arxiv.org/abs/2602.10962v1) | [PDF](https://arxiv.org/pdf/2602.10962v1)

---

### [Photon counting beyond the rotating-wave approximation](http://arxiv.org/abs/2602.10950v1)
**Authors:** Steven Kim, Fabian Hassler  
**Published:** 2026-02-11  
**Updated:** 2026-02-11  
**Categories:** cond-mat.mes-hall, quant-ph  

**Abstract:** Open quantum systems are often described by a Lindblad master equation, which relies on a set of approximations, most importantly the rotating-wave approximation which is only valid for weak damping. In the Lindblad setting, dissipative processes are described through jump operators, distinguishing between absorption and emission of photons. This enables the simple identification of emitted photon...

[View on arXiv](http://arxiv.org/abs/2602.10950v1) | [PDF](https://arxiv.org/pdf/2602.10950v1)

---

---

## Search Configuration

**Queries:**
- quantum circuits AND machine learning
- quantum machine learning AND Fourier
- variational quantum circuits
- parametrized quantum circuits
- quantum neural networks
- barren plateaus quantum
- quantum data encoding
- quantum Fourier analysis

**Categories:** quant-ph, cs.LG, cs.AI
**Lookback Period:** 7 days
